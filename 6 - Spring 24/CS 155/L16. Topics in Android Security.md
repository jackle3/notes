---
Week: Week 8
---
* Title: **A practical approach to the mobile security ecosystem for Android**
	* Guest lecture by Chris Steipp from Meta, working on security for Meta's mobile apps.

# About
* Leads InfoSec for WhatsApp
* Formerly:
	* First security engineer at Wikimedia foundation
	* Started AppSec program at Lyft
	* Worked AppSec at Facebook


## Android and WhatsApp
* Why are we talking about Android?
	* Because Android is the most significant user base in the world.
* During the World Cup, there were 25 million messages per second on WhatsApp.

* WhatsApp is also end-to-end encrypted.
	* However, WhatsApp was exploited by Israeli company NSO Group, a company that exploits software and sells them to governments.
		* The exploit allowed them to spy on 1400 users over a two-week period.
	* WhatsApp sued NSO, currently in legal process.

# Holistic Security
* The security of android apps depends as much on **organizational culture and engineering practices** as it does on **how you secure specific components**.
	* This is the weakest-link principle.

* **Organizational Security**
	* This is related to how security is across the whole organization, including:
		* Security culture
		* Security endpoints, network, build infra
		* Compliance programs
		* Detection programs
* **Secure Development**
	* Engineering practices that promote security
		* E.g. Gates / checkpoints / paved roads / retrospectives
* **Mobile App Security**
	* Specific practices and controls for mobile app development


#  Threat Models
* How do we know what risks to focus on?
* Answer: **Threat Modeling**
	* What are you building?
	* What can go wrong?
	* What should you do about those things that can go wrong?

* In an Android app, the threat model looks like this:
	* The red circles are the trust boundaries -> things we look at and decide whether we trust them or not.
		* E.g. an average app will talk to the Play Store, 3rd party web services, other developers, APIs, etc.
	* We look across these circles and see what can go wrong.
	![[Pasted image 20240606170449.png]]

* You can also use **LLMs** to find the threat models of an application.
	* However, be careful -> some companies like OpenAI use what you give them to train.

## Where to find a list of risks
1. OWASP Top 10 (Mobile)
	![[Pasted image 20240606183554.png]]

2. Android Security Best Practices
	![[Pasted image 20240606183607.png]]
	
3. CWE
4. Company Top 10

# Risks

## Intents & IPC
* Android apps have many components, which need to talk to each other.
* Android makes **accidental exporting** and **exporting to the wrong external apps** easy
![[Pasted image 20240606184409.png]]

* Intents are the primary mechanism for [[L15. Mobile Security#Inter-Process Communication|Inter Process Communication]]
	* If you want one part of the app talk to another part, you use android to pass messages (i.e. intents) around.
	* You can also do these between apps -> external intents.

* Intents can be external (can listen to any app on your phone) or internal (listen to just your own app calling the intents)
	* Developers often **accidentally export their intents** and interfaces by making it external.

### Deeplink Open Redirects
* Also known as Android Nesting Intents
* You call an external intent and package some data.
	* The software then looks at stuff inside the intent and figures out where internally it needs to route things.
	* It would the repackage that intent and call it again.
* This might allow attackers to call internal intents, even though they are outside the system.
```java
@Override
protected void onCreate(Bundle savedInstanceState) {
	// called with myapp://?callback=app%3A%2F%2Ffoo
	Intent incomingIntent = getIntent();
	Uri u = incomingIntent.getData();
	String redirect = u.getQueryParameter("callback");
	Intent intent = new Intent(Intent.ACTION_VIEW, Uri.parse(redirect));
	startActivity(intent);
}
```

* **The problem:** Attacker controlled data (e.g. `String redirect`) is being used to construct an internal intent, which is then called from a privileged context.
* **Solution**: Static Analysis can be used for taint tracking.

### What is static analysis?
* Programs that analyze the source code looking for vulnerabilities.
* Examples are:
	* Linters / minimal context
	* Taint analysis from Source to Sink without a Sanitizer
	* Typically have a **high false positive rate**

* In the example above, we can mark anything that came from the user as *tainted*. Then, we can see if we use tainted data to create intents.

## Web Views
* Web views are basically running a full web browser inside the app, and the Android and JS can talk to each other.
* Web views **have slightly different security properties** than a full browser
	* Developers have many options for how they implement web views.
	* Some options are more or less secure, depending on the use case.

* Web views can be **highly vulnerable to XSS** when JS and callbacks are used.
* **Solutions:**
	* Best practices such as
		* If your app doesn't use JS within a WebView, don't call `setJavaScriptEnabled()`
		* confirm that WebView objects display only **trusted content**.
	* Static Analysis / Taint Tracking
	* Security Reviews
	* Shift Left:
		* More developer training (docs + linters + training)
		* Put out good and secure frameworks

## Logging Private Data
* Developers need visibility into errors. Your app will likely be logging app metrics, statistics, and error conditions.
	* In some cases, they may **log private data**.


* In Android <4.1, apps were allowed to read log files of other apps, and logs would be sent to servers.
* Solution: **don't log anything sensitive.**

* Better solution: **runtime analysis**
	* Collect logs from integration testing & QA
	* Then, look for sensitive data from the test cases
		* Guided fuzzers, and grep for sensitive data in the 

## Running Native Code
* “Out of the 58 in-the-wild **zero-days** for the year, 39 (or 67%) were memory corruption vulnerabilities. *Memory corruption vulnerabilities* have been the standard for attacking software for the last few decades and it’s still how attackers are having success.” - Project Zero

* Android apps are often written in **Java**, which is very slow.
* As such, many big companies write their apps in **C and C++**, and use the Android NDK to compile that into **native code**.

* However, C and C++ are not safe -> a lot of memory corruption risks.

* **Preventions at Scale:**
	* Set compiler flags to prevent exploitation
	* Fuzz everything
		* Issue: setting up good fuzzing harnesses is hard
	* Migrate to safe languages
		* Issue: hard with developer skillset/culture, build processes, dependencies, etc.

## Authentication & Authorization

### Multiple Users, Same App
![[Pasted image 20240606191619.png]]
* For example, WhatsApp is tied to your phone number. However, multiple people often share the same phone.
* **Solution**: encrypt local files between users, require biometrics to log in, etc.

### Making PINs into Keys
![[Pasted image 20240606191837.png]]
* WhatsApp solution:
	* Use hardware security modules that rate limits the number of times a key can be submitted
	* Generates a strong encryption key based off a six-digit pin


## Feature Management
* Engineering will often implement the ability to **roll out features to only a subset** of users for A/B testing or artificially slowing rollout.
	* The “hidden” features can be reverse engineered and enabled.
* Security teams often need to disable specific features without waiting for users to update their apps.
	* **Solution:** push out all the code, and use a configuration file that selectively turns on features to present to the user.


* **Principle:** assume all code in your distributed app is reachable
	* People can reverse engineer apps, and code obfuscation is not reliable.

* **Principle:** implement *intelligent* kill-switches for new features.
	* It’s far less painful to turn off a single feature than force-update many users.
	* To make kill-switches, you can:
		* Make them depend on the platform and its capabilities
		* Operate on a regex of attacker controlled input to detect malicious inputs

## Dependency Management
* If your open/closed source dependency has a security flaw, it may impact your app.

* **Solution:**
	* Software Bill of Materials (SBOM) -> know what libraries your code includes
	* Automation to alert developers when libraries have known issues
		* Issue: there is a lot of false positives; they might not be using vulnerable code.
	* Static analysis for flow analysis
		* This can be used to make the automation above less noisy -> use static analysis to see if it uses vulnerable functions.


## Post-quantum Cryptography
* Once quantum computing works (in 5 or 10 years), the current cryptographic methods (e.g. RSA) will break.


# Organizational Security
* We now talk about things related to the company itself and how that relates to security.

## Culture
* Companies need to have engineering values that include Security/Privacy.
* These values can be used during discussions to appeal for making apps more secure.

## Architecture & Paved Roads
* Setting clear expectations *(Paved Roads)* for problems that have been solved before -> makes most teams want to do the right thing
* If you're in leading company/organization, you will need still need process to get help for new challenges.


# Security
* Your Android App’s security is impacted by the entire ecosystem of your organization’s security.
* This was a (very) quick overview of current threats and controls for securing Android apps. *The specifics will change by the time you graduate*.
	* The threat model is slowly evolving. But hopefully I’ve communicated the principles so you can work these out in the future.

# Questions
* **Worse exploit at WhatsApp:** so far, it's NSO's exploits.
	* They now have a lot of detection mechanisms; has not happened again.
* **Staying up to date after graduation:** it is hard to stay up to date to information after school.
	* You can go to conferences, talk to industry peers, listen as much as you can to other smart people.
	* Favorite conferences are BSidesSF (annual InfoSec conference)