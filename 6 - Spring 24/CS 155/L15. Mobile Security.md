---
Week: Week 8
---
# Phone Threat Models

- **Valuable information** on phones include:
    - Traditional (similar to Desktop PCs)
        - Steal data (e.g., contact list, email, messages, banking information, photos)
        - Phishing
        - Malvertising
        - Join Bots
    - Mobile Specific → phone is becoming an authentication device
        - Identify location, tracking
        - Record phone calls
        - Log SMS (What about 2FA SMS?)
        - Send premium SMS messages

  

## Physical Threats

- Phones are more susceptible to **physical threats**
    - Powered-off devices under complete physical control of an adversary
        - E.g. well-resourced nation states getting control of device
    - Screen locked devices under physical control of adversary (e.g. thieves)
    - Unlocked devices under control of different user
        - E.g. intimate partner abuse → an abusive spouse can install tracking app on phone.
            - How do we design app to stop it from doing harm?
    - Devices in physical proximity to an adversary (with the assumed capability to control radio channels, including cellular, WiFi, Bluetooth, GPS, NFC)
        - E.g. fake cell towers
            - Phones connect to it thinking its real, sending their subscriber ID to authenticate themselves…
            - Controller of cell tower can identify who is in that location.

  

## Untrusted Code

- Android intentionally allows (with explicit consent by end users) installation of application code from arbitrary sources
- Abusing APIs supported by the OS with malicious intent, e.g. spyware
- Exploiting bugs in the OS, e.g. kernel, drivers, or system services
- Mimicking system or other app user interfaces to confuse users
- Reading content from system or other application user interfaces (e.g., screen-scrape)
- Injecting input events into system or other app user interfaces

  

## Network

- The standard assumption of network communication under complete control of an adversary certainly also holds for Android. Assume fist hop (e.g., router) is also malicious.
- Passive eavesdropping and traffic analysis, including tracking devices within or across networks (e.g. based on MAC address or other device network identifiers)
- Active manipulation of network traffic (e.g. MITM on TLS

# AirTags

- AirTags uses BlueTooth to broadcast a specific identifier.
    - This identifier is picked up by Apple devices.
    - These devices relay that location to Apple servers.
    - Apple then reports this AirTag’s location back to the owner of the AirTag.

  

- **Privacy Issue**: Suppose you have an AirTag on you.
    - If the broadcasted identifier is **static** (does not change each time)…
    - An attacker with enough snooping places in a city can tell exactly where you go by tracking your identifier.

  

- **Possible Solution**: Suppose every AirTag has Apple’s public encryption key.
    - The AirTag encrypts its fixed identifier using Apple’s public key with some nonce to make the ciphertext different each time it encrypts.
    - This means the identifier changes each time it is broadcasted.
    - **Problem with this:** people use AirTags to stalk others. Phones need a way to check if it is getting the same signal from an AirTag repeatedly.

  

- **Another solution:** AirTag identifiers change every few hours.
    - This allows attackers to track you for at most a few hours.
    - This also allows phones to detect if you’re being stalked.

  

# Physical Security

  

- To **unlock a device**:
    - Typically need PIN, pattern, or alphanumeric password to unlock device
    - Some applications (e.g., banking apps) also require entering a PIN to access the app

  

- There are some issues with **pattern/swipe code problems**
    - Smudge attacks [Aviv et al., 2010]
        - Entering pattern leaves smudge that can be detected with proper lighting
        - Smudge survives incidental contact with clothing
    - Another problem: entropy
        - People choose simple patterns – few strokes
        - At most 1,600 patterns with <5 stroke

  

## Passcodes

- How do you allow a 4-6 digit PIN and be secure?

  

- **Review: Modern Password Hashing**
    - Choose a random salt `r` and store salted hash
        - Store `(r, H(pw || r ))` and check match against `H(input || r)`
        - Prevents attackers from pre-computing password hashes
    - Making sure to choose an `H` that’s expensive to compute:
        - **SHA-512**: 3,235 MH/s
        - **SHA-3 (Keccak):** 2,500 MH/s
        - **BCryp**t: 43,551 H/s
    - Use one of bcrypt, scrypt, or pbkdf2 when building an application

  

- Phones store the hash of the passcode.
    - When a password is inputted, it hashes it and compares it with the stored hash.
    - Using slow hash functions slows down brute-force approaches to cracking password.
        - **However**: even this is not enough to secure a PIN that is short.

  

### iPhone Password Hashing

- Come up password hashing approach where 4-6 digits takes a very long time to crack, even if the device is physically compromised…
- Additional Constraints:
    - Lots of computation uses up battery (limited resource)!
    - Physical access allows copying secret key off and cracking remotely

  

### iPhone Secure Enclave

- iPhones have a second secure processor known as "secure enclave"
    - Memory is inaccessible to normal OS.
    - Secure boot process that ensures its software is signed.
    - Each secure enclave has an AES key burned in at manufacture.
        - There is no way to copy this AES key with a software-based attack.
- Processor has instructions that allow encrypting and decrypting content using the stored key, but the **key itself is never accessible**.
- The enclave can **rate-limit** the encryption and decryption steps.
    - Slows down brute-force even more than the slow hash functions.

  

### iPhone Unlocking

- User passcode is intertwined with AES key from secure enclave (`K_UID`)
    - Imagine: `key = Encrypt(K_UID, passcode)`.
- This means that the the key to decrypt the device can only be derived on the single secure enclave on a specific phone.
    - Not possible to dump the memory of the device and brute force

  

- The enclave has the HW `K_UID`. They use that to encrypt the `Password` to create the `Class Key`. They use this `Class Key` to encrypt the phone’s filesystem, etc.
    
    ![[attachments/Untitled 78.png|Untitled 78.png]]
    

  

- What prevents asking secure enclave repeatedly to try different passwords?
    - The enclave can **rate-limit** how often it will encrypt using `K_UID`
        - 5 failed attempts → 1 min delay
        - 9 failures → 1 hour delay
        - 10 or more failures → erase phone
    - All of this enforced by firmware on the secure enclave itself — cannot be changed by any malware that controls iOS

  

## Secure Boot Chain

![[attachments/Untitled 1 45.png|Untitled 1 45.png]]

- When an iOS device turns on, it executes code from Boot ROM (read-only memory).
    - Boot ROM is known as the hardware root of trust → implicitly trusted.
    - This code is fixed and immutable → laid down during chip fabrication
- The Boot ROM code contains the Apple Root CA public key.
    - This key is used to verify that the bootloader is signed by Apple.

  

- Boot ROM is first step in chain of trust. Each step ensures that next is signed by Apple.
    1. When the phone starts, it **loads the Boot ROM**.
    2. Then, it loads the LLB and **verifies that the LLB is signed by Apple**.
        1. If the signature is valid, it runs the LLB.
    3. Then, it repeats this with iBoot.
    4. Then, it repeats this with the iOS Kernel.

  

## Software Updates

- To prevent devices from being **downgraded** to older versions that lack the security updates, iOS uses _System Software Authorization_.
    - Device connects to Apple with **cryptographic descriptors** of each…
        - component update (e.g., boot loader, kernel, and OS image)
        - current versions
        - a random nonce
        - device specific Exclusive Chip ID (ECID).
    - Apple signs **device-specific** message allowing update, which boot loader verifies.
        - Boot loader will reject an update with a different ECID → attacker cannot downgrade using an update for another device.

  

## FaceID/TouchID

- Recall that files are encrypted through a hierarchy of encryption keys
- Application files written to Flash memory are encrypted:
    
    - File Key: specific to each file, encrypts all file contents (AES-XTS)
    - Class Key: encrypts File Key (ciphertext stored in metadata)
    - File System Key: encrypts file metadata
    
    ![[attachments/Untitled 2 45.png|Untitled 2 45.png]]
    
- In other words, you need passcode + HW key to get class key, which allows you to read files.

  

- Every time you type in your passcode, the phone will **store the Class Key in memory** of secure enclave → allow you to access file system in session.
    
      
    
    - By default (with no FaceID, TouchID) → **Class Keys are erased from memory** of secure enclave whenever the device is locked or powered off
    
      
    
    - When TouchID/FaceID is enabled → **Class Keys are kept** and hardware sensor sends fingerprint image to secure enclave.
        - All ML/analysis is performed within the secure enclave.
        - TouchID/FaceID only gives the user **access** to the Class Key → does not recompute
        - Note: to forget the class key, click power button five times.

  

### How secure is TouchID?

- Easy to build a fake finger if you have someone’s fingerprint
    - Similar work on FaceID
- The problem: fingerprints are not secret. We cannot replace our fingerprint.
- TouchID is convenient, but more secure solutions exist
    - e.g., unlock phone via bluetooth using a wearable device

  

# Mobile Device Management

- Many companies are now allowing employees to bring/use their own personal devices
    - This means company data resides on devices
- In the past, enterprise workstations were centrally managed.
- How do you handle when users want to bring their own devices?

  

- **MDM**: Manage mobile devices across organization
    
    - Consists of central server and client-side software. Now part of mobile OSes too.
    - Allows:
        - Diagnostics, repair, and update
        - Backup and restore
        - Policy enforcement (e.g. only allowed apps)
        - Remote lock and wipe
        - GPS Tracking
    
    ![[attachments/Untitled 3 45.png|Untitled 3 45.png]]
    

  

  

# Mobile Malware

- Mobile devices are **very different from desktops**
    - Applications are isolated
        - Each runs in a separate execution context
        - No default access to file system, devices, etc.
        - Different than traditional OSes where multiple applications run with the same user permissions!
    - Applications are installed via App Store (and malware spreads)
        - Market: Vendor controlled (Apple) / open (Android)
        - User approval of permissions

  

## Android Isolation

- Based on Linux with sandboxes (SE Linux)
- Applications run as separate UIDs, in separate processes.
- Memory corruption errors only lead to arbitrary code execution in application, not complete system compromise!
- Can still escape sandbox – but must compromise Linux kernel

  

## Rooting

- Rooting allows user to **run applications with root privileges**
    - e.g., modify/delete system files and app, CPU, network management
- Done by exploiting vulnerability in firmware to install a custom OS or firmware image
- Double-edged sword… lots of malware only affects rooted devices

  

## Examples of Malware

![[attachments/Untitled 4 44.png|Untitled 4 44.png]]

  

  

# Mobile Permissions

- Mobile platforms isolate applications for security
    - Smartphones (and other modern OSes) try to prevent such attacks by limiting applications’ default access to:
        - System Resources (clipboard, file system)
        - Devices (e.g., camera, GPS, phone, …)

  

- **Permission Granting Problem**:
    - How can applications access sensitive resources?
    - How should operating system grant permissions to applications?
    - **Standard approach**: Ask the user
        
        ![[attachments/Untitled 5 44.png|Untitled 5 44.png]]
        
        - **Prompts** are disruptive lead to user fatigue
            - E.g. users may just click OK without thinking
        - **Manifests** have no context
            - E.g. users do not understand and may give permissions without knowing.
        - Both are **overly permissive** → once granted permissions, apps can misuse them

  

## Manifests

- In practice, the Android app can request permissions in its manifest.
    - Once that permission is actually necessary, the Android OS prompts the user.
- The OS might also just grant the right if it doesn’t seem dangerous.
    - Manifest also defines what exported endpoints other apps can access.
    - Whole class of malware that takes advantage of this of misconfiguration.

### Are Manifests Usable? (Felt et al)

- TLDR: Manifests on their own are not useable.
    - Android was originally using Manifests. Now it uses Prompts.

![[attachments/Untitled 6 43.png|Untitled 6 43.png]]

![[attachments/Untitled 7 43.png|Untitled 7 43.png]]

![[attachments/Untitled 8 43.png|Untitled 8 43.png]]

  

# Inter-App Communication

- Mobile platforms isolate applications for security, but….
    - Communication: How can applications communicate with each other?

  

## Inter-Process Communication

- **Intents:** Primary mechanism for IPC between app components in Android
    - _Explicit_: specify name: e.g., com.example.testApp.MainActivity
        - E.g. Application A explicitly says it wants to talk com.example.testApp and call its MainActivity function.
    - _Implicit_: Specify action (e.g., ACTION_VIEW) and/or data (URI & MIME type)
        - E.g. I have some data (e.g. URL) and I want any application to display this data.

  
- An implicit intent specifies an action that **can invoke any app** on the device that is able to perform the action.
    - Using an implicit intent is useful _when your app cannot_ perform the action, _but other apps probably can_ and you'd like the user to pick which app to use
    - Note: implicit intents are actually quite dangerous.

  

## Intent Eavesdropping

- Suppose you have a good PDF viewer `goodapp2` and a bad PDF viewer `badapp`.
    - When your app `goodapp1` broadcasts an implicit intent, `badapp` can see that.

![[attachments/Untitled 9 42.png|Untitled 9 42.png]]

  

# Security Dialogues

- Applications often overwhelm users with security alerts.
    - **Problem:** How do we phrase the dialogue to a **non-technical** user?

  

## Example: Internet Explorer

- The dialogues below are for a page served over HTTPS that happen to have an HTTP frame in the page.
    - Most of the page is encrypted, but there is some unencrypted content on the page.

  

- Below is the prompt in IE 6.
    
    - Issues:
        - “Yes”, the arguably less safe option, is highlighted as the default.
        - There is no context. How should the user make this decision?
    
    ![[attachments/Untitled 10 41.png|Untitled 10 41.png]]
    

  

- Below is the prompt in IE 8.
    
    - This is improved significantly from before. It gives context, and the safer option is default.
    - Issues:
        - People don’t like to read. They will probably just ignore the prompt.
    
    ![[attachments/Untitled 11 41.png|Untitled 11 41.png]]
    

  

- Below is the prompt in IE 9.
    
    - This is the best → make the decision for the user to only load the safe content.
    - In the case that the page is broken, give the user the option to enable insecure content.
    
    ![[attachments/Untitled 12 41.png|Untitled 12 41.png]]
    

  

## Interaction Guidelines

- Philosophy:
    - Does the user have unique knowledge the system doesn’t?
        - If the system knows everything the user knows, there is no reason to ask the user…
        - The system should make the decision on its own.
    - Don’t involve user if you don’t need to — leads to alert fatigue
    - If you involve the user, enable them to make the right decision
- Make sure your security dialogs are **NEAT**:
    - Necessary: Can the system take action w/o the user? Does user have more information?
        - If the system can, don’t bother the user.
    - Explained: Does the dialogue include enough information to be understandable?
    - Actionable: Can user make correct decision in malicious and benign situation?
    - Tested: Test with users who haven’t used system in both malicious/benign situations

  

## Example: IE Dialogue for Bad Certificate

- This is the dialogue for a bad certificate.
    - Issues:
        - Regular users don’t know what a certificate is.
        - There is too much text → users won’t read it.

![[attachments/Untitled 13 39.png|Untitled 13 39.png]]

  

## Example: Chrome Dialogue for Bad Certificate

- This is much better than before:
    
    - The **Risk** is very clear and succint.
    - By default, the choice is **Back to safety**.
    
    ![[attachments/Untitled 14 37.png|Untitled 14 37.png]]
    

  

- The user can only move on if they click **Advanced** → adds friction to unsafe actions.
    
    - Fully explains the problem.
    - Makes the choice very small → adds even more friction.
    
    ![[attachments/Untitled 15 35.png|Untitled 15 35.png]]

- These multiple hurdles are good!