---
Week: Week 3
---
# Running untrusted code

- There are a lot of common instances where we need to run untrusted code, or process untrusted inputs.

![[attachments/Untitled 81.png|Untitled 81.png]]

- To safely run untrusted code, we can use a technique called **confinement**.

# Confinement

- This ensures that a misbehaving app cannot harm the rest of the system.
- It can be implemented at many levels.

## Hardware

- Buy another machine, and run the untrusted application on that other machine
    - If one machine is infected, the other is safe.
- The machines are not connected to each other → air gap

![[attachments/Untitled 1 48.png|Untitled 1 48.png]]

- The issue is that it’s difficult to manage → need to carry two machines.

## Virtual machines

- Rather than having two physical machines, we have two virtual machines.

![[attachments/Untitled 2 48.png|Untitled 2 48.png]]

- We still use one hardware. However, we use a hypervisor to separate the two VMs.
    - Each one has it’s own OS, and are virtually disconnected.

## Process

- This is kind of like how Docker and Kubernetes work.

![[attachments/Untitled 3 48.png|Untitled 3 48.png]]

- System Call Interposition: the container interposes on system calls, isolating the process within the OS.

## Threads

![[attachments/Untitled 4 47.png|Untitled 4 47.png]]

- Isolate threads using the same address space via Software Fault Isolation (SFI)

## Application level confinement

- When you run JavaScript or something in the browser, the browser sandboxes that to isolate it from other frames.

![[attachments/Untitled 5 47.png|Untitled 5 47.png]]

# Implementing confinement

- The key component of confinement is a reference monitor.

![[attachments/Untitled 6 46.png|Untitled 6 46.png]]

- It’s very important that the reference monitor is correct → no bugs.
- It is important that it must always be invoked → if the reference monitor dies, the process also dies.

# Example: chroot

- Changes the root directory of your root directory to another location.
    - Once you call `chroot` on a process, that process is now confined to a subspace of the filesystem.
- You must be `root` in order to call `chroot`.
    - After the call, we do `su guest`, which sets the user of the process to `guest`.
        - Prevents the process from undoing what we just did → process can’t call `chroot`

![[attachments/Untitled 7 46.png|Untitled 7 46.png]]

- It effectively jails the user inside a certain directory.

## Escaping from jails

1. It’s quite easy to escape if we know what the `chroot` directory is.
    
    - This is because the attacker can pass relative paths to negate the prefix.
    
    ![[attachments/Untitled 8 46.png|Untitled 8 46.png]]
    
    - To prevent this, we would do input cleansing → before we prepend the prefix, we resolve all the relative paths.
2. We must make it so that `chroot` is only executable by `root` itself.
    
    1. Make sure users cannot jail themselves → this can cause the system to read the wrong essential files.
    
    ![[attachments/Untitled 9 45.png|Untitled 9 45.png]]
    
    - An attacker would create a dummy `/aaa/etc/passwd` that gives you root access.
        - To do so, you would assign userid 0 (root) a password that you know.
    - Then, the attacker can use `chroot` to make `/` point to `/aaa`.
    - The attacker can then call `su root` or `setuid root`
        - The process will then check its `/etc/passwd` , which is actually now `/aaa/etc/passwd`, which would then give the attacker root.
    - Note that `/etc/passwd` stores the hashes of passwords. The attacker can use the `passwd` program to compute the hash to put into `/aaa/etc/passwd`

## Escaping jails as root

- Once the attacker gains root, there are a ton of things they can do to escape the jail and break the system.
    - Create device that lets you access raw disk
    - Send signals to non chrooted process
    - Reboot system
    - Bind to privileged ports

# FreeBSD jail

- This is a better version of `chroot`.
    - Confines the process in both filesystem access and network access.

![[attachments/Untitled 10 44.png|Untitled 10 44.png]]

# Problems with chroot and jail

- One issue is that the policies are too coarse.
    
    ![[attachments/Untitled 11 44.png|Untitled 11 44.png]]
    
- It also does not fully sandbox malicious apps.
    
    ![[attachments/Untitled 12 44.png|Untitled 12 44.png]]
    
- This is okay for daemons, but generally not good for user-side applications → users need access to their own data.

# System call interposition

- This is essentially sandboxing a process.

![[attachments/Untitled 13 42.png|Untitled 13 42.png]]

- We run an untrusted application in a certain process, and heavily monitor all of the system calls made by that process.

## Implementation

- Processes live on top of kernels. When they make a system call, they call into the kernel.

![[attachments/Untitled 14 40.png|Untitled 14 40.png]]

- In the first option, the kernel will check whether that process is allowed to make that system call → uses the tool `seccomp` to perform this.
- In the second option, one process monitors another process. If the monitor sees the application doing something its not allowed, it will kill it.
- In the third option, it partly uses the kernel space and user space.

# Janus - ptrace

![[attachments/Untitled 15 38.png|Untitled 15 38.png]]

- Suppose we are monitoring the browser.
    - We have another process that will call `ptrace` on the browser → this wakes up the monitor every time the browser makes a system call.
- When the browser makes a system call:
    1. The OS wakes up the monitor because the browser made a call.
    2. The OS continues processing the system call as if everything was fine.
    3. If the monitor realizes that the browser can’t make the system call, it will issue a `kill` system call to the browser.

## Policy file

- Each app has a policy file that the monitor can use to figure out what its allowed to do.

![[attachments/Untitled 16 37.png|Untitled 16 37.png]]

## Complications

- This works for one process. However, it gets complicated when the process forks.
- It also needs to remember all the OS state → e.g. needs to know CWD.

![[attachments/Untitled 17 34.png|Untitled 17 34.png]]

## Problems with `ptrace`

![[attachments/Untitled 18 32.png|Untitled 18 32.png]]

- In an ideal world, we only want the sys-call to fail if its not allowed → not possible with `ptrace`, we need to kill the whole process.
- If the OS finishes the sys-call before the monitor kills the process, race condition.
- Alternatively, it can also be exploited using symbolic links.
    - Suppose `me` points to `mydata.dat`, a harmless unprotected file.
    - When process 1 calls `open("me")`, the monitor will check and authorize it.
    - Before the OS finishes execution, another process can change the symbolic link.
    - When the OS finishes, process 1 gets access to `/etc/passwd`
- **The** `**checking for authorization → opening file**` **is not atomic.**

* This is a classic TOCTOU bug.

# SCI in Linux: `seccomp-bpf`

- SCI stands for system call interposition.
- `bpf` stands for Berkeley Packet Filter → originally used for filtering packets in a network.
    - `seccomp` uses this to filter system calls → allows them to write policy of what sys calls are allowed and what are not.

![[attachments/Untitled 19 29.png|Untitled 19 29.png]]

- When the Chrome renderer starts, it will call the `prctl` sys-call → process control.
    - In particular, it sets a `seccomp` policy on itself.
        - It uses `seccomp_mode_filter`, meaning the policy is applied to every sys-call the renderer makes.
        - It uses the policy stores inside the `bpf_policy` file.
    - This gets loaded into the kernel. Then, on every sys-call, the kernel to run this BPF policy file on every sys-call that the renderer makes.
- When a process makes an unauthorized call, the kernel will run the BPF program, then either kill the process or deny the sys-call.

## BPF filters

![[attachments/Untitled 20 29.png|Untitled 20 29.png]]

## Installing a BPF filter

- The first `prctl` below ensures that the process can’t ask for elevated privileges.
- In the second line, it will install the `bpf_policy`.
    - For instance, the policy might be `kill if open() for write`
- In the third line, when the process opens for write, it will be killed.
    - The last line will not be executed.

![[attachments/Untitled 21 26.png|Untitled 21 26.png]]

# Docker

- The docker engine runs on top of the OS.
    - The engine runs containers as processes. Each container is a web server, etc.
    - This ensures that if the process is infected, it will not leak to the rest of the system.

![[attachments/Untitled 22 22.png|Untitled 22 22.png]]

## Sys-call filtering

- Docker allows you to specify your own `seccomp-bpf` filter.

![[attachments/Untitled 23 21.png|Untitled 23 21.png]]

- For instance, the filter above may be for a web server.
    - By default, it denies all actions.
    - However, it whitelists the `accept` system call → allows the server to accept an incoming connection and bind to a socket.

## Confinement flags

- Docker also provides a lot of prebuilt policies that you can run via flags.

![[attachments/Untitled 24 20.png|Untitled 24 20.png]]

- The `cap-drop-all` denies all capabilities, and then you manually whitelist sys-calls.
- You can also limit the number of open files, the number of processes, and the number of restarts on failure → protects from crashes, canary exploits, etc.

# Confinement via VMs

- SCI isolates a process inside a single OS.
- Now, we are isolating an entire VM, which contains an OS inside of it.

![[attachments/Untitled 25 17.png|Untitled 25 17.png]]

## Why so popular?

![[attachments/Untitled 26 14.png|Untitled 26 14.png]]

- In the 1970s - 2000, there was enough computers such that no one needed VMs anymore.
- After 2000, we had too many computers → we need a computer for each type of server.
    - To make this easier, we take all of these different machines, abstract them as VMs, then load them all up on a single hardware architecture.
        - Uses the idea that most of the servers are probably idle, so its a waste to dedicate a whole machine to each server.

## Hypervisor security assumption

![[attachments/Untitled 27 13.png|Untitled 27 13.png]]

## Problem: covert channel

- The VM only prevents the VMs from going past the hypervisor to get to the host OS.
    - However, the VMs themselves may not be fully isolated → covert channels connect between VMs.

![[attachments/Untitled 28 12.png|Untitled 28 12.png]]

- **It’s a lot easier to break a hypervisor than it is to break an air gap**.
    - Suppose the public VM were infected.
    - Using bugs in the hypervisor or something else, the attacker can get malware on the classified VM.
    - They can create a channel between the classified VM and the public VM to leak data.
- If two machines are air gapped, there is no way they can communicate with one another.
    - However, since these two are on the same hardware, its not hard to communicate.

![[attachments/Untitled 29 12.png|Untitled 29 12.png]]

- The attacker can’t create a direct connection. However, they can manipulate the hardware connections to send signals.
    - This can be in the form of CPU activity.
        - On the classified side, they can send bits by either doing nothing or doing an intensive task.
        - On the public side, they can also do the intensive task and measure the time.
            - If it is greater than a threshold, they know the classified side was doing an intensive task, so they know the bit was 1.

# VM isolation in practice

## Cloud

- A cloud service may put the VMs of two customers on the same hardware.
- This can lead to info leaks between the two customers via covert channels, etc.

![[attachments/Untitled 30 12.png|Untitled 30 12.png]]

## End-user

- It’s possible to have an operating system that isolates everything via a virtual machine.

![[attachments/Untitled 31 11.png|Untitled 31 11.png]]

# Hypervisor detection

- Can an OS detect that it is running on top of a hypervisor?

## Applications of detection

![[attachments/Untitled 32 11.png|Untitled 32 11.png]]

## Detection techniques

- There are many different ways to find whether an OS is on a hypervisor.

![[attachments/Untitled 33 11.png|Untitled 33 11.png]]

![[attachments/Untitled 34 9.png|Untitled 34 9.png]]

## Bottom line

![[attachments/Untitled 35 9.png|Untitled 35 9.png]]

# Software Fault Isolation

![[attachments/Untitled 36 8.png|Untitled 36 8.png]]

![[attachments/Untitled 37 8.png|Untitled 37 8.png]]

# Summary

![[attachments/Untitled 38 8.png|Untitled 38 8.png]]