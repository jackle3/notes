---
Week: Week 1
---
# Grading

![Untitled 200.png](../../attachments/Untitled%20200.png)

# Word

![Untitled 1 163.png](../../attachments/Untitled%201%20163.png)

- Tree is the symbol, and the emojis are the idea or thing that it signifies.

# Word Vector

- **Distributional semantics**: A word’s meaning is given by the words that frequently appear close-by

![Untitled 2 162.png](../../attachments/Untitled%202%20162.png)

![Untitled 3 159.png](../../attachments/Untitled%203%20159.png)

# Word2vec

![Untitled 4 154.png](../../attachments/Untitled%204%20154.png)

- Given a word/sentence $w(t)$﻿, try to predict the context.
	- E.g. Suppose the sentence “I really like Palo Alto”
		- Use the word “like” to predict every other word in the sentence, with a size 2 window.
- Every word has two vector representations:
	- When they are in the center position
	- When they are a context for another word

![Untitled 5 151.png](../../attachments/Untitled%205%20151.png)

## Objective Function

![Untitled 6 149.png](../../attachments/Untitled%206%20149.png)

- The likelihood is the product, for every center, of the product of its context words probabilities.

![Untitled 7 145.png](../../attachments/Untitled%207%20145.png)

![Untitled 8 136.png](../../attachments/Untitled%208%20136.png)

- Our goal is to increase $u_o^T v_c$﻿, the similarity of the center $c$﻿ and the context $o$﻿

## Training

![Untitled 9 132.png](../../attachments/Untitled%209%20132.png)

## Derivative of Likelihood

![Untitled 10 126.png](../../attachments/Untitled%2010%20126.png)

![Untitled 11 121.png](../../attachments/Untitled%2011%20121.png)

- We focus on $v_c$﻿ the vector for when $c$﻿ is the center word.

![Untitled 12 118.png](../../attachments/Untitled%2012%20118.png)

![Untitled 13 109.png](../../attachments/Untitled%2013%20109.png)

![Untitled 14 96.png](../../attachments/Untitled%2014%2096.png)

- The first term, $u_o$﻿ is the observed context, while the summation is the expectation of the context.
