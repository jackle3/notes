---
Details: Arrival rate > drain rate
Week: Week 8
---
# Recap

- This is the scenario. The drain rate is 1000 ppm more than the arrival rate.
    
    ![Untitled 128.png](attachments/Untitled%20128.png)
    
- This is what the queue occupancy at the receiver NIC would look like.
    
    - It reports `Idle` until the buffer is full. Then, it starts sending out bits.
    
    ![Untitled 1 92.png](attachments/Untitled%201%2092.png)
    
    - In this case, we found that we needed a buffer size of 10 bits in order to not underflow.
    - If we change our situation further so that:
        - Drain rate of `10.01 Mbit/s`, and arrival rate is `9.99 Mbit/s`, we would need `20 bits` in the buffer.
        - To see this, suppose buffer size was `B` bits.
        - It will take `f` secs to fill up the queue: `f = (1s / 9.99 Mbit) * B bits`
        - Once the buffer is full, it will drain at a rate of `10.01 - 9.99 = 20 Kbit/s`.
        - It will take `e` secs to drain until the buffer is empty: `e = (1s / 20Kbit) * B bits`
        - The buffer will not underflow for `f + e` secs.
        - The total number of bits that arrived from the sender at this time is `9.99 Mbit/s * (f + e)`. We want it to equal the maximum packet size.
            - `9.99 Mbit/s * (f + e) = MTU = 10kbits`
            - `f + e = 1e4 / (9.99 * 1e6) = 0.001001001 seconds = 1.001 ms`
        - We can solve for `B` now.
            - `f + e = 1.001 ms`
            - `(1s / 9.99 Mbit) * B bits` + `(1s / 20Kbit) * B bits` = `1.001 ms`
            - `B * (1/(9.99*1e6) s/bit + 1/(20 * 1e3) s/bit) = 1.001 * 1e-3 s`
            - `B = 1.001 * 1e-3` / `(1/(9.99*1e6) + 1/(20 * 1e3)) = 19.98 bits`

## Parameters

- The parameters that have are in tensions are (tradeoffs) are:
    1. Clock skew tolerance (e.g. +1000 ppm)
        1. An range of tolerable clock skews between arrival and drain rates.
    2. Buffer capacity
    3. Maximum transmission unit (MTU)
        1. maximum size of the packet (and by extension, the payload)
    4. Money (cost per unit)
        1. Cost of increasing the buffer size
        2. Cost of reducing the clock skew tolerance
- The variables are all related.
    - If we want buffer capacity to go down, we would have to reduce clock skew tolerance and/or reduce the MTU
    - If the MTU increases, then the buffer can underflow.
    - If the MTU is really small, it becomes less efficient.

# Efficiency

- The efficiency/goodput of a receiver NIC will be `(MTU - 500 bits) / MTU`
    - The 500 bits correspond to how many bits all of the headers take up. This way, we only measure how much of the payload gets delivered.
    - As MTU decreases, the efficiency goes down.
- If we reduce the clock tolerance and reduce the buffer capacity:
    - We can keep the MTU the same, and the efficiency will be the same.

# Overflow

- We needed a **buffer** to prevent underflow: to bridge between slow arrival and fast drain.
- What if the arrival rate into the receiver rate is bigger than the drain rate out of it?
    - Now, we’re worried about overflow. Since the drain rate is less than arrival rate, the buffer will keep increasing and overflow.

## Example

![Untitled 2 92.png](attachments/Untitled%202%2092.png)

- In the above, the arrival into the receiver NIC is 10.01 Mbit/s, and the drain is 10 Mbit/s.
    - Suppose we have an MTU (max packet len) of `10,000 bits`
- Suppose the sender only sends one packet. If we graph the buffer occupancy size, we have:
    
    - Assuming that we send out the bit as soon as it arrives, the queue occupancy will grow at a rate of `10.01 Mbit/s - 10 Mbit/s = 0.1 Mbit/s = 10 kbit/s`
    - It will stop growing once the packet ends.
        - Packet fully arrives in the NIC after `(1s/10.01Mbit) * 10Kbit = 1e4/1e7 = 0.99 ms`
        - There will be around `10 Kbit/s * 0.99ms = 1e4 * 1e-3 = 1e1 = 10bits` in the buffer once the packet fully arrives.
    - If no other packets are sent, the occupancy will go down at `10 Mbit/s` (drain rate)
        - The buffer will be empty after `10 bit * (1s/10Mbit) = 1e1/1e7 = 1e-6 = 1 microsecond`
    
    ![Untitled 3 92.png](attachments/Untitled%203%2092.png)
    
- However, if the sender sends packets back to back, we will overflow the buffer.
    
    ![Untitled 4 88.png](attachments/Untitled%204%2088.png)
    

## Inter-packet gap

- We can introduce a gap/lag in between packets to prevent overflow.
    - This makes it so that even when the sender sends multiple packets at a higher arrival rate, we still have enough time to fully drain the buffer before next packet.
- In the case below, we introduce an IPG of 1 microsecond, so that it fully drains before receiving the next one.

![Untitled 5 88.png](attachments/Untitled%205%2088.png)

- This reduces our efficiency a bit:
    
    - The efficiency is unit-less → it’s `bits / bits`
    
    $\text{Efficiency} = \frac{\text{MTU} - 500 \text{bits}}{\text{MTU} + \text{IPG} * \text{data rate}}$
    

# How full can you let the buffer get?

- If you don’t know whether its an underflow or an overflow case, how full can the buffer get?
    - If send out bits as soon as it arrives, you can underflow.
    - If you wait and fill up the buffer, you can overflow.
- The ideal is to wait until it gets half full, so that you can account for both cases.
    
    - This also means you need a lower margin that is enough to prevent underflow.
        - We needed 20 bits to handle the underflow case (arrival of 9.99 vs drain of 10.01)
    - You also need an upper margin that is enough to prevent overflow.
        - We needed 20 bits to handle the overflow case (arrival of 10.01 vs drain of 9.99)
    - The total buffer size needs to 40 bits.
    
    ![Untitled 6 87.png](attachments/Untitled%206%2087.png)
    

## Example from quiz

- This is a recap of the situation so far:
    
    Assume a maximum transmission unit (MTU) of 10 kbits, a sender/receiver data rate of 10 Mbit/s ± 1000 ppm, and a sufficient inter-packet gap. The receiver manages its elastic buffer as described in class (waiting until it fills up halfway before allowing the CPU to read bits). What is the minimum necessary size of the receiver's elastic buffer to prevent both underflow and overflow? Express your answer in bits.
    

# Transmitting Audio

- A microphone picks up changes in the air pressure and converts them to an electric signal → a change in voltage on a wire.
    
    ![Untitled 7 84.png](attachments/Untitled%207%2084.png)
    
- This microphone gives a continous electric signal (analog) to the computer. The computer needs to convert it to bits.
    
    - The historical method was to sample points on this signal, and compare it with a baseline zero to approximate it. As you sample more, you get more accurate.
    
    ![Untitled 8 78.png](attachments/Untitled%208%2078.png)
    

## Analog to digital converter (Nyquist)

- Suppose the frequencies of interest fall within the band [-20,000 Hz to 20,000 Hz]
    - The bandwidth of this signal is 40,000 Hz = 40kHz.
    - If you sample that signal 40000 times per second, the number of samples per second is equal to the bandwidth, then you capture mathematically 100% of the information.
        - You can perfectly reconstruct the original analog signal.
- This is how we are able to represent analog signals in a compute, which is digital.

## Encoder

- We are sampling from the analog signal at 40,000 samples per second. We approximate that there are around 16 bits per sample.
    - To transmit this signal, the data rate is 640,000 bits/second = 640 kbits/s
- To make this better, we can use an encoder that compresses our signal to reduce the rate.
    
    ![Untitled 9 74.png](attachments/Untitled%209%2074.png)
    

## Transmitting over network

- The information coming out of this encoder will be picked up by an application, like Zoom.
- Zoom will create a packet/datagram and just send it out.
    - Zoom will be on top of UDP, which is on top of IP, and then send that.

![Untitled 10 70.png](attachments/Untitled%2010%2070.png)

- The maximum payload length is roughly 10kbits.
    - Zoom will accumulate the signal from the microphone and encoder, until it has 1 MTU worth of data. This will take 5 seconds at 2 kbit/s.
    - Then, it will take that full packet and send it to the other user’s Zoom.

![Untitled 11 68.png](attachments/Untitled%2011%2068.png)

- The other user’s Zoom will receive the packer, and immediate begin decoding, then send it through an DAC (digital to analog) to convert the bits back to analog sound signals, which will send it out a loud speaker.
    - That graph will keep decreasing for around 5 seconds, as it plays the packet data.

![Untitled 12 67.png](attachments/Untitled%2012%2067.png)

## End-to-end delay

- Suppose you say “Avocado” through the microphone:
    - It goes thru the ADC, then the encoder, then to Zoom.
    - It will wait at Zoom for somewhere under 5 seconds until the packet is filled,.
    - Then, it gets serialized and sent to the other Zoom.
    - The other Zoom will immediate start playing it
- Assuming that “Avocado” was said at the very start of the packet, the delay will be:
    - 5 seconds waiting at Zoom for the rest of the packet to be filled up.
    - Propagation delay to get sent through the network.
    - Once it arrives to other Zoom, it immediately gets decoded and played.
- That 5 seconds is called **packetization delay**. It’s the delay that the sender chose to impose because it was waiting to fill up the packet.

## Packetization delay

- This is something that the sender chooses, depending on how important minimizing the delay is.
- If you’re doing Zoom, a 5 second delay is far too high. Realistically, you would do like 40 ms delay, so your buffer occupancy at the sender would be sawtoothed.

![Untitled 13 65.png](attachments/Untitled%2013%2065.png)

- The buffer at the receiver side will be the opposite of this. It will fill up, and then drain.
    
    - The danger of this receiver side is underflow. If the next packet does not come in time before the current packet is fully played, we will lead to underflow.
        - This can be caused by **jitter** → the end-to-end delay is variable, due to queueing delay in the network. The variability of the delay caused by queueing is called **jitter**.
    
    ![Untitled 14 61.png](attachments/Untitled%2014%2061.png)
    
    - The solution is to have an elastic buffer (aka de-jitter buffer) on the receiver Zoom.
        - Once it receives packets, it just keeps it, until its comfortable that there won’t be underflow or overflow.
    
    ![Untitled 15 59.png](attachments/Untitled%2015%2059.png)
    
- The tradeoff is that the overhead is now worse. The packets are smaller, so the end-to-end delay is less, but there is more overhead since you send more packets.