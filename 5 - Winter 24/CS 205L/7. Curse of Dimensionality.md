---
Week: Week 4
---
- Happens when typical methods fail when the dimensions scale upwards.
    - A lot of solutions for engineering or physics are designed for three dimensions. Higher dimensions tend to cause these solutions to fail.

# Numerical Integration (Quadrature)

- To approximate the integral, we usually just take samples, break it up into chunks, and take the area of the chunks to get the area under the curve.

![[attachments/Untitled 65.png|Untitled 65.png]]

- As the number of samples increase, meaning the width of chunks decrease, the approximation gets more correct.
- The result of the error is dependent on how well we approximated the function (polynomial interpolation)

# Newton-Cotes Quadrature

- This is the standard approach we learned when learning calculus.
- On each subinterval, pick points (1 point is a box, 2 points is a trapezoid, etc) and to reconstruct the function and approximate the area.

![[attachments/Untitled 1 32.png|Untitled 1 32.png]]

- This method really only works up to 4 dimensions, and only works well up to 3 dimensions.

## Symmetric Cancellation

- In the example below, the function is linear.
- Doing the box method (picking 1 point, 0th degree) gets you the same answer as doing the trapezoid method (picking 2 points, 1st degree)

![[attachments/Untitled 2 32.png|Untitled 2 32.png]]

## Piecewise approximation

![[attachments/Untitled 3 32.png|Untitled 3 32.png]]

- Notice that the constant approximation can integrate linear (degree 1), and the quadratic approximate can integrate cubic (degree 3)

## Local and global error

- In order to do Newton-Cotes approximation to integrate, we need many boxes
    - The more boxes we have, the lower the error, since we’re closer to the actual function.
- In high dimensions, this fails because we can’t put enough boxes.

![[attachments/Untitled 4 31.png|Untitled 4 31.png]]

- If we’re using a $p$﻿ degree polynomial to interpolate, then we have $O(h^{p+1})$﻿ errors since we don’t have the full Taylor expansion.
- The local error is how bad we do per interval. It’s calculated by multiplying the error in the height by the error in the width.
- The global error is the total error that we have over all the intervals. It’s less than the local error because the number of intervals is $O(1 / h)$﻿
- When you double the intervals (in the 1D case, this means doubling the work and halving the interval sizes), the error decreases based on the degree of $p$﻿
    - If $p$﻿ is zero, meaning its a 1st order accurate method, the error halves.
    - If $p$﻿ is one, meaning its a 2nd order accurate method, the error goes down by a fourth.

## Midpoint / Trapezoid Rules

![[attachments/Untitled 5 31.png|Untitled 5 31.png]]

# Gaussian Quadrature

- Similar to Newton-Cotes but we derive the best location to put our points when calculating the intervals.
    - In Newton-Cotes, we kind of just put the points either at the midpoint or at the ends.

![[attachments/Untitled 6 30.png|Untitled 6 30.png]]

# Two Dimensions

![[attachments/Untitled 7 30.png|Untitled 7 30.png]]

## Domain Approximation Errors

- Supposed we want to find the area of the red shape $A$﻿. Notice the error between the triangle mesh and the actual shape.

![[attachments/Untitled 8 30.png|Untitled 8 30.png]]

- You can’t approximate boundaries very well in 2D.
- If we wanted to make the approximation better, we can halve the interval size, making the triangles half as big. This would make the error go down by a factor of four.
    - However, to halve the interval size, we would essentially be connecting the midpoints of the intervals.
    - Notice that this now makes four triangles instead of one triangle, basically quadrupling our amount of work.

![[attachments/Untitled 9 29.png|Untitled 9 29.png]]

## Integrating over Sub-regions

- In two dimensions, calculating the integral is essentially getting the volume under the purple surface instead of area under the curve.

![[attachments/Untitled 10 28.png|Untitled 10 28.png]]

# Curse of Dimensionality

- Consider a 1st order accurate method, which is essentially a 0th order polynomial (constant)
    - The error is linear with the interval size.

![[attachments/Untitled 11 28.png|Untitled 11 28.png]]

- With a 2nd order accurate method, which is a linear function, it’s better but still bad.
    - The error is quadratic with the interval size. This means we can reduce the error by more with the same amount of work.

![[attachments/Untitled 12 28.png|Untitled 12 28.png]]

- These methods are intractable in high dimensions → takes years to run.

![[attachments/Untitled 13 27.png|Untitled 13 27.png]]

- Methods like polynomial or piecewise interpolation is Newton-Cotes style

# Monte Carlo Method

![[attachments/Untitled 14 26.png|Untitled 14 26.png]]

## Newton-Cotes Approach

- In this approach, you just draw smaller and smaller triangles and add up the areas.

![[attachments/Untitled 15 25.png|Untitled 15 25.png]]

## Monte Carlo Approach

- Recall that we know the area of the circle and the area of the box.

$\frac{A_{circle}}{A_{box}} = \frac{\pi}{16} \to \pi = 16(\frac{A_{circle}}{A_{box}})$

- The area of the box can be approximated by the total number of blue and red dots.
- The area of the circle can be approximated by the number of blue dots.

![[attachments/Untitled 16 25.png|Untitled 16 25.png]]

- You only have to know whether the dots were inside the circle or outside it.

## Method Summary

![[attachments/Untitled 17 22.png|Untitled 17 22.png]]

- Regardless of the dimension, you need four times the amount of work to get half the error.
    - Don’t have the curse of dimensionality as mentioned before.

# Machine Learning Implications

![[attachments/Untitled 18 20.png|Untitled 18 20.png]]