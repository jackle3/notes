---
Week: Week 7
---
# Roadmap

![[attachments/Untitled 57.png|Untitled 57.png]]

# Approximating Functions

![[attachments/Untitled 1 24.png|Untitled 1 24.png]]

![[attachments/Untitled 2 24.png|Untitled 2 24.png]]

- In this case, $x$﻿ and $y$﻿ are your inputs.
- The parameters are $c$﻿ → one set of parameters for all $x$﻿ and $y$﻿ pairs.

![[attachments/Untitled 3 24.png|Untitled 3 24.png]]

- We want to choose parameters such that for all $i$﻿, we minimize the function $f$﻿
    - This just means we get close to the actual data.

# Choosing a norm

- We need to pick a norm for each $f(x_i, y_i; c)$﻿

![[attachments/Untitled 4 23.png|Untitled 4 23.png]]

- Notice that this unconstrained optimization, where it only depends on $c$﻿.
    - $\hat{f}(c)$﻿ is the thing we want to minimize. It is a scalar valued function.
    - This cost function is a nonlinear least squares problem.

# Optimization

![[attachments/Untitled 5 23.png|Untitled 5 23.png]]

- Constrained optimization is much harder than unconstrained optimization.
    - People often just fold the constraints into the cost function, and then do unconstrained.

# Conditioning for Optimization

- As you get closer to critical points, it is much harder to get to that critical point because the function becomes locally flat → can’t find a search direction.

![[attachments/Untitled 6 22.png|Untitled 6 22.png]]

- You lose about half of the tolerance precision when you minimize the function instead of finding its roots.
    - It’s poorly conditioned for regular nonlinear optimization.

# Nonlinear Systems of Equations

![[attachments/Untitled 7 22.png|Untitled 7 22.png]]

# Constrained Optimization

- As mentioned previously, we can fold the constraints into our cost function to do unconstrained optimization.

![[attachments/Untitled 8 22.png|Untitled 8 22.png]]

- Each term of $g(c)^T D g(c) = d_i \cdot g_i(c)^2$﻿. It’s just basically adding more stuff related to $c$﻿.

## Lagrange Multipliers

- This is another method to solve constrained optimization.
    - We add another variable $\eta$﻿, called Lagrange multipliers, and minimze from there.
    - Now, you have two variables in your optimization: $c$﻿ and $\eta$﻿

![[attachments/Untitled 9 22.png|Untitled 9 22.png]]

- When you take the gradient, you have to take the gradient wrt to all the $c$﻿’s and all the $\eta$﻿’s
    - The top block row is wrt $c$﻿. The bottom block row is wrt $\eta$﻿
    - The equality constraints are automatically staisfied by the critical point equation.

![[attachments/Untitled 10 22.png|Untitled 10 22.png]]

![[attachments/Untitled 11 22.png|Untitled 11 22.png]]

## Examples

![[attachments/Untitled 12 22.png|Untitled 12 22.png]]

- Below is the contours of this equation. The steepest descent direction is the negative gradient of $\nabla \hat{f}$﻿. This was calculated previously in the slide above.
    
    - At the critical point, it is orthogonal to the constraint surface. This means in order to improve any further, we’d have to jump off the line.
    - The arrow is the direction of the minus gradient.
    
    ![[attachments/Untitled 13 21.png|Untitled 13 21.png]]
    
    ![[attachments/Untitled 14 20.png|Untitled 14 20.png]]