---
Week: Week 7
---
# Roadmap

![Untitled 57.png](../../attachments/Untitled%2057.png)

# Approximating Functions

![Untitled 1 24.png](../../attachments/Untitled%201%2024.png)

![Untitled 2 24.png](../../attachments/Untitled%202%2024.png)

- In this case, $x$﻿ and $y$﻿ are your inputs.
- The parameters are $c$﻿ → one set of parameters for all $x$﻿ and $y$﻿ pairs.

![Untitled 3 24.png](../../attachments/Untitled%203%2024.png)

- We want to choose parameters such that for all $i$﻿, we minimize the function $f$﻿
    - This just means we get close to the actual data.

# Choosing a norm

- We need to pick a norm for each $f(x_i, y_i; c)$﻿

![Untitled 4 23.png](../../attachments/Untitled%204%2023.png)

- Notice that this unconstrained optimization, where it only depends on $c$﻿.
    - $\hat{f}(c)$﻿ is the thing we want to minimize. It is a scalar valued function.
    - This cost function is a nonlinear least squares problem.

# Optimization

![Untitled 5 23.png](../../attachments/Untitled%205%2023.png)

- Constrained optimization is much harder than unconstrained optimization.
    - People often just fold the constraints into the cost function, and then do unconstrained.

# Conditioning for Optimization

- As you get closer to critical points, it is much harder to get to that critical point because the function becomes locally flat → can’t find a search direction.

![Untitled 6 22.png](../../attachments/Untitled%206%2022.png)

- You lose about half of the tolerance precision when you minimize the function instead of finding its roots.
    - It’s poorly conditioned for regular nonlinear optimization.

# Nonlinear Systems of Equations

![Untitled 7 22.png](../../attachments/Untitled%207%2022.png)

# Constrained Optimization

- As mentioned previously, we can fold the constraints into our cost function to do unconstrained optimization.

![Untitled 8 22.png](../../attachments/Untitled%208%2022.png)

- Each term of $g(c)^T D g(c) = d_i \cdot g_i(c)^2$﻿. It’s just basically adding more stuff related to $c$﻿.

## Lagrange Multipliers

- This is another method to solve constrained optimization.
    - We add another variable $\eta$﻿, called Lagrange multipliers, and minimze from there.
    - Now, you have two variables in your optimization: $c$﻿ and $\eta$﻿

![Untitled 9 22.png](../../attachments/Untitled%209%2022.png)

- When you take the gradient, you have to take the gradient wrt to all the $c$﻿’s and all the $\eta$﻿’s
    - The top block row is wrt $c$﻿. The bottom block row is wrt $\eta$﻿
    - The equality constraints are automatically staisfied by the critical point equation.

![Untitled 10 22.png](../../attachments/Untitled%2010%2022.png)

![Untitled 11 22.png](../../attachments/Untitled%2011%2022.png)

## Examples

![Untitled 12 22.png](../../attachments/Untitled%2012%2022.png)

- Below is the contours of this equation. The steepest descent direction is the negative gradient of $\nabla \hat{f}$﻿. This was calculated previously in the slide above.
    
    - At the critical point, it is orthogonal to the constraint surface. This means in order to improve any further, we’d have to jump off the line.
    - The arrow is the direction of the minus gradient.
    
    ![Untitled 13 21.png](../../attachments/Untitled%2013%2021.png)
    
    ![Untitled 14 20.png](../../attachments/Untitled%2014%2020.png)