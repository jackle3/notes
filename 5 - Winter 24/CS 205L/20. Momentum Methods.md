---
Week: Week 9
---
- This is referring to ADAM → this is where we have adaptive learning rates and momentum.

# Path through Parameter Space

- Each line on the path is a discrete entry on the iteration scheme. We essentially teleport from one contour to the next → we don’t actually move along the lines.

![[attachments/Untitled 54.png|Untitled 54.png]]

## Continous Path vs Discrete Path

- Traditional steepest descent can be thought of as a discrete path.
- We can try to represent a continous path thorugh parameter space, turning it into an ODE.

![[attachments/Untitled 1 21.png|Untitled 1 21.png]]

- Treat the optimization problem as a **continous path** through parameter space.
    - Think of your location on the path as a position, and the motion through it as a velocity.
    - Using that, we can represent the optimization problem as an ODE

# ODEs

- Instead of teleporting from one step of the path to the next, we follow the path continously.

![[attachments/Untitled 2 21.png|Untitled 2 21.png]]

- The red is an ODE for gradient descent.
    - The velocity $dc/dt$﻿ is simply the steepest descent direction: the negative gradient.
    - This is reminiscent of physics. At any point, the velocity is simply going downhill as fast as you can.

## Gradient Flow

- The specific ODE we’re looking at for optimization is **gradient flow**.
- The rate of the change of the parameters, $dc/dt$﻿, should be equal to the steepest descent direction.
    - This is also called the velocity through parameter space.
    - If we write it all out, we see that there is an ODE for each parameter.

![[attachments/Untitled 3 21.png|Untitled 3 21.png]]

# ODEs: Families of Solutions

- Small perturbations in the starting condition can affect the solution. Notice that the curves are pretty similar in shape.

![[attachments/Untitled 4 20.png|Untitled 4 20.png]]

- Small perturbations in the input/starting location can lead to larger differences in the output.
    - Since we solving the ODE numerically, small numerical errors (which are inherent with solving by computer) can cause us to jump to a different curve, changing our solution.

![[attachments/Untitled 5 20.png|Untitled 5 20.png]]

- Bifurcation means two nearby solutions diverge to two different solutions.

## Posedness

- Some ODEs are bad, and you can never hope to solve them on a computer.
    - The left one is ill-posed because small changes lead to large changes in the solution.

![[attachments/Untitled 6 19.png|Untitled 6 19.png]]

- The posedness depends on the Jacobian matrix.
    - If there is a positive eigenvalue, then it will cause divergence (bad)
- There is one Jacobian matrix for every point that you walk through on your path.
    - You want all eigenvalues to be non-positive for all $t$﻿ in order to be well-posed.

## Posedness for Systems

- If we think about the Jacobian matrix of the function $F$﻿.
    - In order to have a well-posed problem, we need the eigenvalues to be negative or zero.

![[attachments/Untitled 7 19.png|Untitled 7 19.png]]

## Stability and Accuracy

- If it’s a well-posed ODE, then you can solve it numerically on a computer.

![[attachments/Untitled 8 19.png|Untitled 8 19.png]]

- Remember that the whole parameter space is $\R^n$﻿. Your path/trajectory is in $\R^1$﻿.
    - All you need is well-posedness on your $\R^1$﻿ trajectory. If it fails, start somewhere else in parameter space and hope that you have a well-posed trajectory.

# Forward Euler Method

- One way of solving an ODE, without having to analytically integrate. It’s a numeral method.
    - It’s effectively doing gradient descent.
    - Note that $\frac{c^{q+1} - c^q}{\Delta t}$﻿ is the same as $\frac{dc}{dt}$﻿

![[attachments/Untitled 9 19.png|Untitled 9 19.png]]

- The first step is to approximate the derivative $c’$﻿ using finite difference.
    - Note that this is the derivative in $c$﻿ (the parameter) with respect to time.
    - Also, $f$﻿ here is any ODE. However, for us, $f$﻿ would be the gradient flow.
- The recursive update is effectively line search for gradient descent.
    - $\Delta t$﻿ is the step size for the parameters → this is a hyperparameter
    - $c' =f(t^q, c^q) = -\nabla \hat{f}(c(t))$﻿ is actually the gradient of the cost function.

![[attachments/Untitled 10 19.png|Untitled 10 19.png]]

- Note that since we are essentially truncating the Taylor series, there is truncation error.
    - This is related to the quadrature from before.
        - The number of time steps is $(t_f - t_o) / \Delta t$﻿. Since $t_f - t_o$﻿ is constant, we can say the number of steps taken is $O(1 / \Delta t)$﻿
        - Each step has an error of $O(\Delta t^2)$﻿.
        - This makes it so that the overall error is $O(\Delta t)$﻿ → **1st order accurate.**

# Runge-Kutta (RK) Methods

- You can get higher order accuracies by using more of the Taylor series.
    - All of these methods are just built upon forward euler.

![[attachments/Untitled 11 19.png|Untitled 11 19.png]]

- For the 2nd order method:
    - $k_1$﻿ is exactly the same as the Forward-Euler term.
    - $k_2$﻿ is gotten from evaluating the function $f$﻿ with the Forward-Euler update.
        - It uses the fact that $c^{q+1} = c^q + \Delta t k_1$﻿
    - Then, you average the two steps. You basically look ahead a little bit.
    - Notice that you basically have to do double the amount of work. However, you also get 4 times more accurate because it’s 2nd order.
- For the 2nd order method:
    - $k_1$﻿ is just forward euler.
    - $k_2$﻿ is taking half a forward-euler step forward from $k_1$﻿
    - $k_3$﻿ is taking half a forward-euler step forward from $k_2$﻿
    - $k_4$﻿ is taking a full forward-euler step forward from $k_3$﻿
    - This is basically looking around the area to get better accuracies and gradients.

# Total variation diminishing Runge-Kutta

![[attachments/Untitled 12 19.png|Untitled 12 19.png]]

- This second order method is the same as before, but presented different.
    - You take two forward euler steps.
    - Then, you take the midpoint between the two within parameter space, and use that as your updated $c^{q+1}$﻿
- The third order method here is the best. It’s usually more stable than fourth order.

# Stability Analysis: Choosing $\Delta t$﻿

- Below is related to the learning rate problem from the PSET.

![[attachments/Untitled 13 18.png|Untitled 13 18.png]]

- We want to choose $\Delta t$﻿ such that the result $c^{q+1}$﻿ still exponentally decays, getting smaller and smaller as we increase $q$﻿.
    - Notice that we only consider $\lambda < 0$﻿ since we can’t divide by zero.
    - However, $\lambda = 0$﻿ is still okay because the update equation is just:
        - $c^{q+1} = (1 + \Delta t \cdot 0)^{q+1} c^0 = c^0$﻿
- Note also that we can only move forwards in this. $\Delta t$﻿ will always be positive.

![[attachments/Untitled 14 17.png|Untitled 14 17.png]]

  

## Gradient Flow with Forward Euler

- The update equation for gradient flow ODE is **exactly the same** as 1D line search.
    - The difference is that $\Delta t$﻿ is chosen by the stability restriction.
    - In 1D line search, it’s chosen by solving a 1D minimization or root finding.
        - This was from Lecture 15. $\Delta t$﻿ was written as $\alpha$﻿ there.

![[attachments/Untitled 15 17.png|Untitled 15 17.png]]

## Adaptive Time Stepping

- Also known as adaptive learning rate, which is what ADAM does.

![[attachments/Untitled 16 17.png|Untitled 16 17.png]]

### Adagrad, Adadelta, RMSprop

- There have been some ML methods designed at getting an adaptive learning rate.

![[attachments/Untitled 17 15.png|Untitled 17 15.png]]

- Adagrad was found to mess up gradient descent, because it changed the search direction.
    - Since we had per-parameter learning rates, we were moving more/less in certain directions.
    - This means our actualy movement path did not follow the actual gradient flow.

# Implicit Methods

- The whole point of implicit methods it to greatly relax the time step restriction (the one where $\Delta t$﻿ has to be small).
    - Allows you to take larger time steps, but at the expense of more work per step.
    - As a result, explicit methods are often faster, since they take more but smaller and simpler time steps.
- Also, because you now take larger time steps, the accuracies are more likely to be off.

![[attachments/Untitled 18 13.png|Untitled 18 13.png]]

## Backward (Implicit) Euler

- Typically, $c^{q+1}$﻿ will be part of some nonlinear equation, which requires you to solve for it.
    - The only difference is that the right-hand-side is now based on $t^{q+1}$﻿ instead of $t^q$﻿.
- We can now see the issue with non-linear equations. We want to solve for $c^{q+1}$﻿, but its mixed into both the left side $\frac{c^{q+1} - c^q}{\Delta t}$﻿ and the right side $f(t^{q+1}, c^{q+1})$﻿

![[attachments/Untitled 19 12.png|Untitled 19 12.png]]

- The stability condition holds regardless of the value of $\Delta t$﻿.
    - This is because it’s on the denominator, and $\lambda < 0$﻿ and $\Delta t > 0$﻿.
    - Stability does not mean accuracy though. Choosing a wrong $\Delta t$﻿ will be stable, but it will not produce an accurate result.
- The steady state solution is where $dc / dt = 0$﻿.
- Stiff ODEs are ODEs where part of the solution is very high frequency in a small time step, which does not contribute much.
    - It would be fine to damp this high frequency stuff.

## Implicit SGD

- This method starts with backward euler on the gradient descent ODE.
- Then, since it’s stochastic, it only evalutes a gradient for one piece of data at a time. This allows it to solve for $c^{q+1}$﻿ a tiny bit easier.

![[attachments/Untitled 20 12.png|Untitled 20 12.png]]

## Trapezoidal Rule

![[attachments/Untitled 21 9.png|Untitled 21 9.png]]

- Recall that for backward euler, if the time step is too big, you get damping in your solutions.
- In the trapezoidal rule, if the time step is too big, you get **oscillations.**

# Momentum

- The difference between standard ODE methods and momentum methods is that;
    - **Momentum** looks at a system of ODEs instead of a single ODE. It makes another set of unknowns besides $c'$﻿

![[attachments/Untitled 22 7.png|Untitled 22 7.png]]

- It remembers the forces throughout history that acted on the object.
    - If you throw a ball through the air, it will go down because gravity is acting on it **but it will also keep going horizontally**, since it remembers the force you gave it and it has momentum.
- This method creates a separate set of ODEs for the momentum of the parameters.
    - This method attempts to help it get out of local optima or plateaus.

## Recall: Newton’s Second Law

![[attachments/Untitled 23 7.png|Untitled 23 7.png]]

## Recall: First Order Systems

![[attachments/Untitled 24 7.png|Untitled 24 7.png]]

- Thinking it this way allows us to just forget about $V$﻿ as a variable.
    - The only variable is now $X$﻿, and $V$﻿ is just $X'$﻿

## Momentum Methods

- We basically build momentum/inertia to incorporate the effects of prior search directions.
    - Adagrad and all the other methods tried to do this in a hacky way.

![[attachments/Untitled 25 6.png|Untitled 25 6.png]]

## Momentum-style Gradient Flow

- Instead of directly setting the velocity, we use momentum. We treat the gradient as forces acting on the velocity, updating its value between iterations.
    - It’s a smoother path now.
        - If you are moving left and the gradient points down, steepest descent would instantly turn down.
        - In this method, it would slowly curve down, holding on to your inertia.

![[attachments/Untitled 26 5.png|Untitled 26 5.png]]

- The results at the bottom are our ODEs.
    - Recall that in traditional forward Euler, the only ODE was $c' \approx - \nabla \hat{f}(c^q)$﻿
    - Now, we have an ODE for $c'$﻿ and also an ODE for $v'$﻿.
        - The gradient information is now incorporated into the velocity update.
        - The velocity is used to calculate the parameter update. This allows it to still incorporate prior search directions.
    - The change in position in parameter space is the **velocity**.
    - The change in velocity is based on the current gradient descent direction.
        - As you move around, the velocity incorporates more and more information about prior gradients.
        - This gives it a time history and more stability.

# ML Momentum Method

- This first does forward Euler on $v$﻿. Then, it uses that result to do backward Euler on $c$﻿.
    - There is no non-linear equations being solved here.

![[attachments/Untitled 27 4.png|Untitled 27 4.png]]

- We can combine these two terms which gets us the below.
    - Even more, if we say that $\Delta t$﻿ and $\Delta t^2$﻿ are two different parameters, we can have $\alpha$﻿ and $\beta$﻿ as new parameters.
    - Notice that this mirrors the physics equation $x = v_i t + \frac{1}{2}at^2$﻿ → $\nabla f(c^q)$﻿ is $a$﻿

![[attachments/Untitled 28 3.png|Untitled 28 3.png]]

- If we make $\beta = \Delta t$﻿, we can retrieve a modified gradient flow equation. The only extra part here is the $\alpha v^q$﻿, which is the history dependent velocity term.
    
    ![[attachments/Untitled 29 3.png|Untitled 29 3.png]]
    
    - The issue with this is that if we take a really small step, meaning $\Delta t$﻿ is small, our $v^{q+1}$﻿ can become very large, which doesn’t make much sense.

# Nesterov Momentum

- The first step is a forward Euler step. Notice that the right hand side only depends on $v^{q}$﻿.

![[attachments/Untitled 30 3.png|Untitled 30 3.png]]

![[attachments/Untitled 31 3.png|Untitled 31 3.png]]

- Then, the gradient is evaluated at this new location, and that’s used in the original ML Momentum method from before.
    - Basically, instead of using the gradient at the current position, we take a predictor step forwards and use the gradient from there.

![[attachments/Untitled 32 3.png|Untitled 32 3.png]]

- In essence, both methods are very similar.
- They both use the exact same formula. The difference is the gradient.
    - The original evaluates at the current state → 1st order accurate.
    - Nesterov evaluates at some new predicted state → aiming for 2nd order accurate

# Physics/ODE Consistency

- The first equation is fine. As $\Delta t$﻿ approaches zero, we still have

$\frac{c^{q+1} - c^q}{\Delta t} \approx v^q \quad \to \quad c' = v$

- The second equation, which is there in both Nesterov and the original method, will converge to infinity as $\Delta t$﻿ goes to zero.
    - Whatever $v^q$﻿ is, $v^{q+1}$﻿ will be around same number but scaled to infinity.

![[attachments/Untitled 33 3.png|Untitled 33 3.png]]

- This can be fixed pretty easily. Simply set $\beta = \hat{\beta} \Delta t^2$﻿.
    - This makes it so that the velocity change actually includes the forces $\nabla f$﻿
        - As $\Delta t$﻿ goes to zero, those forces vanish, which is what you want for ODE consistency.
    - We’ve still retained the parameter $\hat{\beta}$﻿ that we can control.

![[attachments/Untitled 34 3.png|Untitled 34 3.png]]

- Recall that in the original formulation, $\alpha = \Delta t$﻿ and $\beta = \Delta t^2$﻿. The only difference here is that we introduced a parameter $\hat{\beta}$﻿ that defines how strong the forces $\nabla f$﻿ are.

# Adam

![[attachments/Untitled 35 3.png|Untitled 35 3.png]]

# Constant Acceleration Equations

![[attachments/Untitled 36 2.png|Untitled 36 2.png]]

## Newmark Methods

- Be careful with how you discretize position and velocity in differential equations.

![[attachments/Untitled 37 2.png|Untitled 37 2.png]]

## Central Differencing

![[attachments/Untitled 38 2.png|Untitled 38 2.png]]

## Staggered Position and Velocity

![[attachments/Untitled 39 2.png|Untitled 39 2.png]]

## Staggered Central Differencing

![[attachments/Untitled 40 2.png|Untitled 40 2.png]]