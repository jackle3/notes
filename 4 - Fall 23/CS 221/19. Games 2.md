---
Date: 2023-10-30
---
![[Games_2.pdf]]

# Limited Depth Search

- For efficiency, we stop at a certain max depth $d_{\max}$﻿

![[attachments/Untitled 115.png|Untitled 115.png]]

# Evaluation Function

![[attachments/Untitled 1 81.png|Untitled 1 81.png]]

# Alpha-beta Pruning

- Maintain bounds to prune trees that we know for sure won’t be used for the final result.

![[attachments/Untitled 2 81.png|Untitled 2 81.png]]

![[attachments/Untitled 3 81.png|Untitled 3 81.png]]

## Example

![[attachments/Untitled 4 77.png|Untitled 4 77.png]]

## Move Ordering

- Pruning depends a lot of the order of actions. To save on time complexity, we can choose a certain ordering to improve performance.

![[attachments/Untitled 5 77.png|Untitled 5 77.png]]

# TD-learning

- Learning evaluation functions automatically from data

$\text{Eval}(s) = V(s;\mathbf{w})$

![[attachments/Untitled 6 76.png|Untitled 6 76.png]]

## Generating Data

- To learn, we can synthetically generate data by following the current policies

![[attachments/Untitled 7 74.png|Untitled 7 74.png]]

## Learning

![[attachments/Untitled 8 69.png|Untitled 8 69.png]]

![[attachments/Untitled 9 66.png|Untitled 9 66.png]]

## Algorithm

![[attachments/Untitled 10 64.png|Untitled 10 64.png]]

# Comparison with Q learning

![[attachments/Untitled 11 62.png|Untitled 11 62.png]]

![[attachments/Untitled 12 61.png|Untitled 12 61.png]]

# Simultanous Games

- This is games without any turns, like rock paper scissors.

## Payoff Matrix

![[attachments/Untitled 13 59.png|Untitled 13 59.png]]

## Strategies (policies)  
  

![[attachments/Untitled 14 55.png|Untitled 14 55.png]]

## Game Evaluation

![[attachments/Untitled 15 53.png|Untitled 15 53.png]]

## Mixed and Pure Strategy

- If the first is played a mixed strategy, then the second player can attain the minimum with a pure strategy.

![[attachments/Untitled 16 51.png|Untitled 16 51.png]]

![[attachments/Untitled 17 48.png|Untitled 17 48.png]]

## Minimax Theorem

![[attachments/Untitled 18 46.png|Untitled 18 46.png]]