---
Date: 2023-10-11
---
# Applications of search problems

## Route finding

- Finds paths between destination A to destination B
- To pick the path, there is often an **objective**:
    - E.g. shortest path, fastest path, most scenic path
- There are also **actions** it can do, such as moving through the world.
    - E.g. go straight, turn left, turn right

## Robot motion planning

- **Objectives** could be the fastest path from one location to another location.
    - Can also be most energy efficient, safest, etc
- The **actions** can be acceleration and throttle.
    - Actions be actual physical things, such as the movement of the robot.
    - It can also be to translate and rotate joints, etc

## Solving puzzles

- Puzzles like the rubiks cube can also be a search problem.
- The objective is to reach a certain configuration
- The actions are to move pieces or to rotate the cube, etc

# Reflex-based vs State-based

![[attachments/Untitled 112.png|Untitled 112.png]]

- The output of state based models is a sequence of actions that follow each other.

# Modeling search problems

## Farmer

- A farmer wants to get his cabbage, goat, and wolf across a river. He has a boat that only  
    holds two, including the farmer. He cannot leave the cabbage and goat alone or the goat and wolf alone.  
    **How many river crossings** does he need?
- There are multiple actions the farmer can do, duplicated both ways for each way of the river crossing.
    
    ![[attachments/Untitled 1 78.png|Untitled 1 78.png]]
    

### Search tree

![[attachments/Untitled 2 78.png|Untitled 2 78.png]]

- The edges are the actions we can take, and the nodes are the states we can be at.
- The states in red are bad states, since it violates the conditions of the problem.
- Each side of the `||` are who is on each side of the river.
- Using this search tree, the **minimum number of crossings is 7**.

### Defining the search problem

- `s_start` → the initial starting state
- `Actions(s)`
    - A function that takes a state `s` and gives us all the possible actions we have from that state.
- `Cost(s, a)` → the cost of taking action `a` from state `s`
    - In this case the cost was `1`, for a river crossing.
- `Succ(s, a)`
    - Tells us what the next state is (where we end up at after taking the action at that particular state).
- `IsEnd(s)` → tells us whether we’re at an end state (can be either win or lose end state)

## Transportation

![[attachments/Untitled 3 78.png|Untitled 3 78.png]]

- We have $n$﻿ blocks. Our goal is to travel from block $1$﻿ to any other block.

![[attachments/Untitled 4 74.png|Untitled 4 74.png]]

- From any state, our actions are to either walk, or to take the tram. What sequence of actions should we do?

### Code definition of problem

![[attachments/Untitled 5 74.png|Untitled 5 74.png]]

- We combine the `successor` and the `cost` function in this case, because they both kind of calculate and return the same thing, just different parts of the result.
- There are `10` blocks. If we start from state `9`, we can only walk.

# Tree search

- We can think of state problems as searching through a tree, where the branching is the actions we can take.

![[attachments/Untitled 6 73.png|Untitled 6 73.png]]

## Backtracking search

- It just traverses through the tree with backtracking. It tries every node and every solution. It it doesn’t work, it backtracks, and tries another node.
- It has to **exhaustively** search through every path, because once it finds a solution it doesn’t know if that’s the best solution.

![[attachments/Untitled 7 71.png|Untitled 7 71.png]]

- Backtracking **does not have any assumptions on cost.**
    - It’s going to traverse through every single path regardless of the cost of each action on the path.
- The memory complexity is calculated as the things we need to store and remember.
    - In this case, it’s storing the path from a solution to the root node.

### Algorithm

![[attachments/Untitled 8 66.png|Untitled 8 66.png]]

![[attachments/Untitled 9 63.png|Untitled 9 63.png]]

## Depth-first search

- Very similar to backtracking search, but it assumes that the cost of all actions are zero.

![[attachments/Untitled 10 61.png|Untitled 10 61.png]]

- Once we find a solution, we don’t care about any other solution because the cost to get to **every solution** is just zero.
- The space is still the same. It still needs to remember the path that it took to get from the root to the solution node.
    - During traversal, we only consider one path at a time.
- The worst case time complexity is still the case, but it can be much better since we can end early.

## Breadth-first search

![[attachments/Untitled 11 60.png|Untitled 11 60.png]]

- BFS explores one layer of the tree at a time. It processes the whole layer, then moves to the next layer of the tree.
- Allows us to find the shortest path easily — the path that takes the least number of actions.
    - As soon as we find a solution, we know it will be the best solution since we travel layer by layer.
    - This is because the cost of all actions are uniform.
- The time complexity is much better now.
    - Since we don’t need to explore further layers of the tree once we find a solution, we just need to explore the layers before and containing the solution.
- The space complexity is worse now.
    - We need to remember every node that we went explored before we got to the solution.
        - This is because we need to remember how to expand the tree to get to the next layer, in case we don’t find a solution in the current layer.
        - Not just the solution path, but the entire tree layers before it.

## DFS with Iterative Deepening

- Assumes we have a cost that is positive and constant between all edges
- It goes down the tree iteratively level by level.
    - For each level, it does a full DFS search of what it has access to at that level.

![[attachments/Untitled 12 59.png|Untitled 12 59.png]]

- We see savings in space. We no longer have to keep track of every node that we passed in history, just the depth.

## Summary of Tree search algorithms

![[attachments/Untitled 13 57.png|Untitled 13 57.png]]