---
Date: 2023-11-27
---
# Overview

![Untitled 93.png](../../attachments/Untitled%2093.png)

- Syntax defines the set of valid formulas
- Sematics specifies the meaning of a formula, which can be a set of configurations of the world where the formula holds (this is what we care about_

# Syntax

![Untitled 1 60.png](../../attachments/Untitled%201%2060.png)

- Every propositional symbol is a formula. They are called atomic formulas, or **atoms**
    
    ![Untitled 2 60.png](../../attachments/Untitled%202%2060.png)
    
- We can make larger formulas by recursively combining smaller ones with connectives
    
    ![Untitled 3 60.png](../../attachments/Untitled%203%2060.png)
    
- Note that the syntax is just symbols. It doesn’t have a meaning yet.
    
    ![Untitled 4 59.png](../../attachments/Untitled%204%2059.png)
    

# Semantics

![Untitled 5 59.png](../../attachments/Untitled%205%2059.png)

## Model

![Untitled 6 58.png](../../attachments/Untitled%206%2058.png)

- In other words, it’s an assignment of truth values (true or false) to each propositional symbol.

![Untitled 7 58.png](../../attachments/Untitled%207%2058.png)

## Interpretation function

- The semantics of a formula is given by an interpretation function.
- It takes a formula $f$﻿ and a model $w$﻿, and returns whether $w$﻿ satisfies $f$﻿

![Untitled 8 57.png](../../attachments/Untitled%208%2057.png)

- The interpretation function is done recursively. Given a complex formula, it just breaks it into smaller and smaller chunks along the connectives, and evaluates the return values.
    
    ![Untitled 9 56.png](../../attachments/Untitled%209%2056.png)
    
    - For the base case, if we just have a proportional symbol (e.g. A), then the result of the interpretation function is just the assignment for that symbol in $w$﻿.

## Set of models

- Each formula and model has an interpretation $I(f, w) \in \{0, 1\}$﻿

![Untitled 10 54.png](../../attachments/Untitled%2010%2054.png)

- **Compact representation:** a formula compactly represents models
    - With the formula $\text{Rain} \lor \text{Wet}$﻿, there are four possible assignments (models)
    - That formula compactly represents the set of models below:
        
        ![Untitled 11 54.png](../../attachments/Untitled%2011%2054.png)
        
        - The red boxes give semantic → it’s the models that satisfy $f$﻿

## Knowledge Base

- The conjunction of all formulas that have been considered so far.
- The set of models of the knowledge base is the intersection of the set of models that satisfy each formula.

![Untitled 12 54.png](../../attachments/Untitled%2012%2054.png)

- The KB specifies **constraints** on the world. $\mathcal{M}$﻿(KB) is the set of all worlds (models/assignments) that satisfy those constraints.

### Examples

- If you know that it is either raining or snowing, and that there is traffic, your models are constrained to the intersection of those.
    
    ![Untitled 13 52.png](../../attachments/Untitled%2013%2052.png)
    
    ![Untitled 14 50.png](../../attachments/Untitled%2014%2050.png)
    
- If you know that it is raining, and that if it rains then it’s wet, then the set of models is constrained to those where it is raining and wet.
    
    ![Untitled 15 48.png](../../attachments/Untitled%2015%2048.png)
    

## Expanding the KB

- Each **formula** is a fact that you know, and the **knowledge** is just the collection of those facts. Each fact narrows down the space of possible models, so the more facts you have, the fewer models you have.
- Intuitively, every formula imposes a constraint on the world, which decreases the set of possible worlds.

![Untitled 16 46.png](../../attachments/Untitled%2016%2046.png)

- There are three cases when asking how much $f$﻿ shrinks the set of models $\mathcal{M}(KB)$﻿

### Entailment

![Untitled 17 43.png](../../attachments/Untitled%2017%2043.png)

- If $f$﻿ added no new information, then $\mathcal{M}(KB) \cap \mathcal{M}(f)=\mathcal{M}(KB)$﻿
    - In other words, the set of models does not change.
- In the example above, if we know that it is raining and snowing, and then you tell us that it is snowing, that adds no new information
- If a KB entails a formula $f$﻿, it means that if all the formulas in the KB are true, then that formula $f$﻿ must also be true in those same models

### Contradiction

![Untitled 18 41.png](../../attachments/Untitled%2018%2041.png)

- After adding $f$﻿, no model satisfies the constraints after adding $f$﻿
- If we think about it, this is the same as $\mathcal{M}(KB) \subseteq \mathcal{M}(\neg f)$﻿, because $\mathcal{M}(KB)$﻿ is now inside the region excluding $\mathcal{M}(f)$﻿
    - This tells us that contradiction is equivalent to $KB \vDash \neg f$﻿

![Untitled 19 38.png](../../attachments/Untitled%2019%2038.png)

### Contingency

![Untitled 20 37.png](../../attachments/Untitled%2020%2037.png)

### Summary

![Untitled 21 34.png](../../attachments/Untitled%2021%2034.png)

## Tell operation

- We can now tell the knowledge base, and use the responses based on which case the new information $f$﻿ falls into.

![Untitled 22 30.png](../../attachments/Untitled%2022%2030.png)

## Ask operation

- We can also use the knowledge base to ask questions about it. We can simply pass in our question as a formula $f$﻿, and reply based on how that formula changes the knowledge base.

![Untitled 23 27.png](../../attachments/Untitled%2023%2027.png)

- If asking the formula didn’t change the knowledge base, then that is entailment, meaning we know the formula to be true.

## Probabilistic interpretaton

![Untitled 24 26.png](../../attachments/Untitled%2024%2026.png)

- The uncertainty here is captured by the probability of a certain model, $P(W = w)$﻿
    
    ![Untitled 25 23.png](../../attachments/Untitled%2025%2023.png)
    
- We can interpret the result of the probabilities pretty easily:
    
    ![Untitled 26 20.png](../../attachments/Untitled%2026%2020.png)
    
    - If the probability is 0, then we are in a contradiction, so the response is no.
    - If the probabiliy is 1, then we are in an entailment, so the response is yes.
    - Otherwise, we don’t know. This is a contingent situation.

## Satisfiability

![Untitled 27 18.png](../../attachments/Untitled%2027%2018.png)

- A knowledge base is satisfiable if there exists some model that satisfies all the formulas $f \in KB$﻿
- We can reduce Ask[f] and Tell[f] to a satisfiability argument.
    
    ![Untitled 28 16.png](../../attachments/Untitled%2028%2016.png)
    
    ![Untitled 29 15.png](../../attachments/Untitled%2029%2015.png)
    
    ![Untitled 30 15.png](../../attachments/Untitled%2030%2015.png)
    

## Model checking

![Untitled 31 13.png](../../attachments/Untitled%2031%2013.png)

- The process of checking satisfiability in just solving a CSP!
    
    ![Untitled 32 13.png](../../attachments/Untitled%2032%2013.png)
    

![Untitled 33 13.png](../../attachments/Untitled%2033%2013.png)

# Inference Rules

![Untitled 34 11.png](../../attachments/Untitled%2034%2011.png)

- Premises are the evidence, as well as the rules that you have about your situation.
- The conclusion is the result given your premises.

![Untitled 35 11.png](../../attachments/Untitled%2035%2011.png)

- Note that $f_1, \dots, f_k$﻿ and $g$﻿ are all formulas. These inference rules operate on syntax.
- The rule says that if the premises are in the KB, then you can add the conclusion to the KB.

![Untitled 36 10.png](../../attachments/Untitled%2036%2010.png)

## Forward Inference Algorithm

![Untitled 37 10.png](../../attachments/Untitled%2037%2010.png)

![Untitled 38 10.png](../../attachments/Untitled%2038%2010.png)

- Once we add the conclusion formula $g$﻿ to the knowledge base, it can then be the premise of other inference rules, which then generate more formulas (conclusions) to add.

## Derivation

![Untitled 39 9.png](../../attachments/Untitled%2039%209.png)

- Alternatively, KB derives or proves a formula $f$﻿ if by blindly applying rules, we can eventually add $f$﻿ to the KB
    
    ![Untitled 40 9.png](../../attachments/Untitled%2040%209.png)
    

## Example

![Untitled 41 7.png](../../attachments/Untitled%2041%207.png)

- Wet is derived from the premises Rain and Rain → Wet, since Wet is the conclusion.
- Slippery is derived from the prmeises Wet and Wet → Slippery in the second iteration, since Wet was added previously.

## Semantics

- Semantics gives an objective notion of truth. It provides us with $\mathcal M$﻿, the set of satisfiable  
    models for each formula  
    $f$﻿ or knowledge base.
    - This defines a set of formulas which are defined to be true, formulas that entail the knowledge base (meaning that the formulas are already known given the KB)
- Inference rules generates a set of formulas by repeated application.

![Untitled 42 7.png](../../attachments/Untitled%2042%207.png)

## Soundness

![Untitled 43 6.png](../../attachments/Untitled%2043%206.png)

- A set of inference rules is sound if using those inference rules, the set of derived formulas is a subset of the set of true/entailed formulas.
- In other words, the inference rules do not derive any formulas that are false.

![Untitled 44 6.png](../../attachments/Untitled%2044%206.png)

![Untitled 45 6.png](../../attachments/Untitled%2045%206.png)

## Completeness

![Untitled 46 6.png](../../attachments/Untitled%2046%206.png)

- A set of inference rules is complete if using those inference rules, the set of derived formulas is a superset of the set of true/entailed formulas.
- In other words, the inference rules derive every true formula, and possibly false formulas too.

![Untitled 47 6.png](../../attachments/Untitled%2047%206.png)

- Semantically, it must be true that it is wet, because we know that it is raining, and that if it is raining or snowing, then it is wet.
- However, modus ponens can’t derive wet because the or in the syntax doesn’t work.