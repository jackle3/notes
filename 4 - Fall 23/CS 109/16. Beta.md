---
Date: 2023-11-01
---
# Definition

- This is the random variable for probabilities → gives uncertainty to the probability of some even
- Any parameter for a “parameterized” random variable can be thought of as a random variable
    - The beta is for the parameter $p$﻿ of the Binomial RV
- It can be used when you can **run trials and see whether you succeed or fail**
    - We can use beta to find a distribution on what the probability of a success was.
    - Basically, the parameter **p** to a binomial can be a random variable.

# Example

- Let $X$﻿ be the probability of flipping a heads, given that we flipped 9 heads and 1 tail.
    
    $f(X = x | H=9, T=1)$
    
    where $0 \leq x \leq 1$﻿$0 < x < 1$﻿, meaning $x$﻿ is a continous random variable for the probability.
    
- By Bayes Theorem, the above equation becomes
    
    $P(H=9, T=1 | X=x) f(X = x) \times K$
    
- If we have no information about $X$﻿, a pretty good prior belief is to say that it’s uniform.
    - All probabilities are equally likely. It’s also nice because no matter for the value of $x$﻿, the result of the PDF is just 1 in this case: $1 / (b - a) = 1 / ( 1 - 0) = 1$﻿

![Untitled 185.png](attachments/Untitled%20185.png)

- In addition, the left term is just a simple binomial problem. It asks that with probablity $x$﻿ of getting heads, what is probability of getting $9$﻿ heads in $10$﻿ total trials.

![Untitled 1 148.png](attachments/Untitled%201%20148.png)

## Generalized Example

![Untitled 2 147.png](attachments/Untitled%202%20147.png)

- $c$﻿ is whatever number ends up making the equation integrate to 1, to make it a valid pdf.

![Untitled 3 144.png](attachments/Untitled%203%20144.png)

![Untitled 4 139.png](attachments/Untitled%204%20139.png)

# Definition, Expectation, Variance

![Untitled 5 137.png](attachments/Untitled%205%20137.png)

# Prior was Beta

- Remember that $X$﻿ was the random variable for the probability.
- It is very possible that our prior belief about $X$﻿ was a beta random variable.
    
    ![Untitled 6 135.png](attachments/Untitled%206%20135.png)
    
- If the prior was a beta, the result is still a beta with different parameters.
    
    ![Untitled 7 131.png](attachments/Untitled%207%20131.png)
    

## Beta(1, 1) is uniform

![Untitled 8 122.png](attachments/Untitled%208%20122.png)

## Laplace smoothing

![Untitled 9 118.png](attachments/Untitled%209%20118.png)

- Beta(a, b) implies a - 1 successes and b - 1 failures when we are assuming a uniform prior to
    - If we instead had a different prior of say Beta(2, 1), that would imply a - 2 successes and b - 1 failures

# Another example

![Untitled 10 113.png](attachments/Untitled%2010%20113.png)

- In this case, we can have multiple priors for the working 80% of the time.
    - The first prior is very confident.
    - The second is medium confidence.
    - The last one is minimal confidence.

![Untitled 11 109.png](attachments/Untitled%2011%20109.png)

# Thompson Sampling

![Untitled 12 106.png](attachments/Untitled%2012%20106.png)