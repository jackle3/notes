---
Date: 2023-11-03
---
# IID Random Variables

- Short for independent and identically distributed RVs

![[attachments/Untitled 188.png|Untitled 188.png]]

- It is important to note that they must all be independent.

![[attachments/Untitled 1 151.png|Untitled 1 151.png]]

# Motivating Examples

## Zero Sum Games

- Remember back to the example with the warriors and whether they would win or not.
    
    ![[attachments/Untitled 2 150.png|Untitled 2 150.png]]
    
    - We couldn’t analytically solve this back then since we didn’t know how to compare the two random variables. We had to sample.
- Now, we can use the idea of adding random variables to solve this
    
    ![[attachments/Untitled 3 147.png|Untitled 3 147.png]]
    

## Sum of Dice

![[attachments/Untitled 4 142.png|Untitled 4 142.png]]

- Each $X_i$﻿ is IID because dice are independent and have the same distribution.

# Adding Random Variables

- When we add random variables, we get another random variable.
- **Convolution**: basically a synonym for adding random variables

![[attachments/Untitled 5 140.png|Untitled 5 140.png]]

![[attachments/Untitled 6 138.png|Untitled 6 138.png]]

## General Formula

![[attachments/Untitled 7 134.png|Untitled 7 134.png]]

# Sum of Independent Binomials

![[attachments/Untitled 8 125.png|Untitled 8 125.png]]

# Sum of Independent Normals

![[attachments/Untitled 9 121.png|Untitled 9 121.png]]

# Sum of Independent Poissons

![[attachments/Untitled 10 116.png|Untitled 10 116.png]]

# Virus Infections Example

![[attachments/Untitled 11 112.png|Untitled 11 112.png]]

- There are many approaches for this problem.
    - We can use the general formula for adding RVs with the original binomials.
    - We can also approximate it as normals, which is what we did above.

# Sum of Independent Uniforms

![[attachments/Untitled 12 109.png|Untitled 12 109.png]]

- Using the general formula for adding RVs, we have the following
    
    ![[attachments/Untitled 13 101.png|Untitled 13 101.png]]
    
    - Notice that the bounds is 0 to 0.2, because if we went past that then $f(Y=0.2-i)$﻿ becomes invalid.
    - In addition, the answer to that integral is just $0.2$﻿ because both the PDF equations are just equal to 1.

## General Formula for two RVs

![[attachments/Untitled 14 89.png|Untitled 14 89.png]]

- In the example above, $X$﻿ and $Y$﻿ are independent and identically distributed.

# Central Limit Theorem

- Sum of $n$﻿ IDD random variables is a normal with
    - Mean $n \times E[X_i]$﻿
    - Variance $n\times\text{Var}(X_i)$﻿
- This theorem applies to any type of random variable.

![[attachments/Untitled 15 85.png|Untitled 15 85.png]]

- This is why the binomial PMF looks like a Gaussian distribution: it’s just equal to a sum of Bernoulli random variables.
    
    ![[attachments/Untitled 16 79.png|Untitled 16 79.png]]
    
    ![[attachments/Untitled 17 74.png|Untitled 17 74.png]]
    

## Example with sum of uniform RVs

![[attachments/Untitled 18 67.png|Untitled 18 67.png]]

![[attachments/Untitled 19 60.png|Untitled 19 60.png]]

![[attachments/Untitled 20 57.png|Untitled 20 57.png]]

![[attachments/Untitled 21 51.png|Untitled 21 51.png]]

# Mean of IID Random Varibles

![[attachments/Untitled 22 47.png|Untitled 22 47.png]]

- By the CLT, the mean of IID are distributed normally.

![[attachments/Untitled 23 44.png|Untitled 23 44.png]]

# Runtime Example

- We want to estimate the average running time for a program
    
    ![[attachments/Untitled 24 40.png|Untitled 24 40.png]]
    
- We can use the mean of the trials as our estimate. In this case, the mean is normally distributed.
- This problem wants us to find $n$﻿ such that the difference between our estimate $\bar{X}$﻿ and the actual time $t$﻿ is within $0.5$﻿, with a 95% certainty.

![[attachments/Untitled 25 35.png|Untitled 25 35.png]]

![[attachments/Untitled 26 30.png|Untitled 26 30.png]]

- Notice that $\bar{X} - t$﻿ only changes the mean, not the variance. This is because $t$﻿ is not a random variable. We’re just shifting the center of $\bar{X}$