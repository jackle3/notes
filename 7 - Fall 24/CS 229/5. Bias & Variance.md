********
# Bias and Variance Curve
![Pasted image 20241028215951](attachments/Pasted%20image%2020241028215951.png)
![Pasted image 20241028215957](attachments/Pasted%20image%2020241028215957.png)
![Pasted image 20241029220303](attachments/Pasted%20image%2020241029220303.png)
![Pasted image 20241028221914](attachments/Pasted%20image%2020241028221914.png)

* **Bias** is when a model has a strong preconception about the data.
	* Aka: the bias of a model is the test error even if we were to fit it to a very (say, infinitely) large training dataset
	* E.g. a linear model has a strong bias that the data is linear (can't fit non-linear data)
	* Also known as **underfitting** ⟶ training error is large.
	* **algorithm’s tendency to consistently learn the wrong thing by not taking into account all the information in the data**
* **Variance** is when a model has high variability when the data changes.
	* E.g. fitting a high order polynomial to linear data.
	* Also known as **overfitting** ⟶ training error is small but test error is large; bad generalization.
	* **algorithm’s tendency to learn random things irrespective of the real signal by fitting highly flexible models to the noise/error in the data too closely**
		 ![500](attachments/Pasted%20image%2020241028220125.png)

* This also applies for classification, where we can focus on the decision boundary.
![Pasted image 20241028220204](attachments/Pasted%20image%2020241028220204.png)
## Key Equation
![Pasted image 20241029220226](attachments/Pasted%20image%2020241029220226.png)
![Pasted image 20241028222208](attachments/Pasted%20image%2020241028222208.png)
![Pasted image 20241031132801](attachments/Pasted%20image%2020241031132801.png)
![Pasted image 20241031132812](attachments/Pasted%20image%2020241031132812.png)
# Diagnostics
* Machine learning involves a lot of diagnostic and debugging.
![Pasted image 20241014120505](attachments/Pasted%20image%2020241014120505.png)


## High Variance
![Pasted image 20241028220314](attachments/Pasted%20image%2020241028220314.png)
* In the high variance case, you tend to overfit to small datasets.
	* As $n$ grows, training error **increases** because it can't fit every data point as well.
	* As $n$ grows, test error **decreases** because your model generalizes better.
* Variance can be reduced by using larger training sets.
* When you have high variance, **test error is much higher than training error.**
	* Large gap between test and training error.
![700](attachments/Pasted%20image%2020241014122052.png)
* The desired performance might be something like human level performance. Suggests that if you **extrapolate further, test error will eventually reach desired**.

## High Bias
![Pasted image 20241028220322](attachments/Pasted%20image%2020241028220322.png)
* In the high bias case, you tend to underfit.
* When you have high bias, **train error is almost the same as test error**, with both higher than the human baseline.
	* Small gap between test and train error.
![Pasted image 20241023133748](attachments/Pasted%20image%2020241023133748.png)

## High Bias and High Variance
![Pasted image 20241028220345](attachments/Pasted%20image%2020241028220345.png)

## Diagnostic Example
![Pasted image 20241028220335](attachments/Pasted%20image%2020241028220335.png)
# Regularization
* When a model is overfitting (i.e. high variance), regulization can reduce variance/overfitting.
![Pasted image 20241028220441](attachments/Pasted%20image%2020241028220441.png)
* In regularization, we change the cost function to make overfitting more difficult.
	* When using the regularized loss $J_{\lambda}(\theta)$, we aim to find a model that both fit the data (a small loss $J(\theta)$) and has a small model complexity (a small $R(\theta)$).
![Pasted image 20241028222304](attachments/Pasted%20image%2020241028222304.png)

## L1 Regularization
* Also known as LASSO, this regression function encourages sparsity.
$$
R(\theta) = ||\theta||_{1}
$$
## L2 Regularization
![Pasted image 20241029220353](attachments/Pasted%20image%2020241029220353.png)
* In this case, we penalize large magnitudes of $\theta$.
$$
R(\theta) = \frac{1}{2} ||\theta||_{2}^2
$$
### Setup
Let’s assume we have a loss function $J(\theta)$ that we want to minimize, with the addition of an L2 regularization term:
$$
J_{\text{reg}}(\theta) = J(\theta) + \frac{\lambda}{2} \|\theta\|_2^2
$$
where $\frac{\lambda}{2} \|\theta\|_2^2 = \frac{\lambda}{2} \sum_{i=1}^n \theta_i^2$.

### Gradient of the Regularized Loss
To perform gradient descent, we need to take the gradient of $J_{\text{reg}}(\theta)$ with respect to $\theta$:
$$
\nabla_\theta J_{\text{reg}}(\theta) = \nabla_\theta J(\theta) + \nabla_\theta \left( \frac{\lambda}{2} \|\theta\|_2^2 \right)
$$

Since $\|\theta\|_2^2 = \sum_{i=1}^n \theta_i^2$, we have:
$$
\nabla_\theta \left( \frac{\lambda}{2} \|\theta\|_2^2 \right) = \lambda \theta
$$

Thus, the gradient of the regularized loss is:
$$
\nabla_\theta J_{\text{reg}}(\theta) = \nabla_\theta J(\theta) + \lambda \theta
$$
### Gradient Descent Update with L2 Regularization
Using gradient descent with learning rate $\alpha$, the update rule for $\theta$ becomes:
$$
\theta \leftarrow \theta - \alpha \nabla_\theta J_{\text{reg}}(\theta)
$$
Substituting the expression for $\nabla_\theta J_{\text{reg}}(\theta)$:
$$
\theta \leftarrow \theta - \alpha \left( \nabla_\theta J(\theta) + \lambda \theta \right)
$$
Expanding this, we get:
$$
\theta \leftarrow \theta - \alpha \nabla_\theta J(\theta) - \alpha \lambda \theta
$$
### Simplifying to Show the Weight Decay Factor
We can factor out $\theta$ from the regularization term:
$$
\theta \leftarrow \theta \left( 1 - \alpha \lambda \right) - \alpha \nabla_\theta J(\theta)
$$
Therefore, each update shrinks $\theta$ by a factor of $(1 - \alpha \lambda)$ in addition to the usual gradient step. This term $(1 - \alpha \lambda)$ is often referred to as the **weight decay factor**.
### Summary
The gradient descent update with L2 regularization is:
$$
\theta \leftarrow \theta \left( 1 - \alpha \lambda \right) - \alpha \nabla_\theta J(\theta)
$$
where $(1 - \alpha \lambda)$ is the decay factor that reduces $\theta$ in each step, effectively implementing weight decay.

## Visualizing Regularization
![Pasted image 20241029220748](attachments/Pasted%20image%2020241029220748.png)

## Varying Lambda
![Pasted image 20241028220708](attachments/Pasted%20image%2020241028220708.png)
![Pasted image 20241028220446](attachments/Pasted%20image%2020241028220446.png)
* As we increase $\lambda$, the curve smoothens out.
	* As $\lambda \to \infty$ the parameters $\theta$ approaches zero because the magnitude is penalized.
![Pasted image 20241028220535](attachments/Pasted%20image%2020241028220535.png)


## Preventing Collapse
* In the previous example, having a too high $\lambda$ led to collapse.
![Pasted image 20241028220640](attachments/Pasted%20image%2020241028220640.png)
* We can prevent this and instead have it approach the mean of the data.
![Pasted image 20241028220644](attachments/Pasted%20image%2020241028220644.png)
![Pasted image 20241028220650](attachments/Pasted%20image%2020241028220650.png)

## Choosing Lambda
* Each choice of $\lambda$ is a different model because it changes the cost function. In other words, its a **hyperparameter**.
* We usually choose lambda using cross validation!

# Train/Dev/Test
* We often split the dataset into splits to help us choose our model, # of features, or hyperparameters.
![Pasted image 20241028220803](attachments/Pasted%20image%2020241028220803.png)
* We train on the training set.
* Then evaluate on the dev set (to pick model, hyperparams, etc)
	* Model params $\theta$ **does not** train on the dev set.
* **Note:** the dev set is a better estimate of the test error than the training set. However, **it is not unbiased**.
	* bc we fit the hyperparams (e.g. $\lambda$) to the dev set.

## Test Set
* Having a fully unseen test set gives an unbiased estimator of the error.
![Pasted image 20241028220907](attachments/Pasted%20image%2020241028220907.png)

## K-fold Cross Validation
* This is often used for small datasets ⟶ we take the training data and split into $k$ equal chunks.
![Pasted image 20241028220948](attachments/Pasted%20image%2020241028220948.png)
* This average error tells us how well our model does.
* Once we've picked our hyperparams through this process, it's common to retrain on all the data.

## Leave-one-out Cross Validation
![Pasted image 20241028221020](attachments/Pasted%20image%2020241028221020.png)

# Model Selection
* You have a set of models:
	1. Evaluate each model using hold-out CV, k-fold CV, or leave-one-out CV
	2. Pick the best model with minimum error on dev set
	3. (optional) retrain model on all the data

# Model Size
* Without regularization, large models tend to **overfit (high variance)** on small datasets
![400](attachments/Pasted%20image%2020241028221136.png)
* With reglarization, the curve tends to look like this ⟶ much less overfitting
![400](attachments/Pasted%20image%2020241028221202.png)
* Nowadays, with a sufficiently fast computer, there is no harm in using a bigger model with more parameters.
