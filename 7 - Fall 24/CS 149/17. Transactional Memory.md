
# Abstractions for Synchronization
* Previous topic: machine-level atomic operations for synchronization
	* E.g. test-and-set, fetch-and-op, compare-and-swap, load linked-store conditional
* We used these to construct higher-level synchronization primitives:
	* Locks, barriers
	* Lock-free data structures
	* We've seen how its challenging to produce correct programs using these primitives (easy to create bugs that violate atomicity, deadlock, etc.)

* Today: using transactional memory as a higher-level synchronization primitive
## Whats the Problem with Locking?
* Locks force trade off between performance (degree of concurrency) and correctness (races, deadlocks, etc)
* To get a highly-concurrent program, you need either:
	* fine-grained locking ⟶ better but more likely to create bugs
	* coarser-grained locking ⟶ lower concurrency, but higher chance of correctness

## Review: Ensuring Atomicity via Locks
* Suppose you are doing deposits. If there can be concurrent deposits, we need ot synchronize it.
![[Pasted image 20241203131353.png]]

# Programming with Transactions
* Instead of explicitly locky, you **declare a set of operations/a region of instructions** to be atomic.
	* You leave it up to the system to implement this atomicity.
![[Pasted image 20241203131411.png]]

## Declarative vs. Imperative Abstractions
* **Declarative**: programmer defines what should be done
	* E.g. execute all these independent 1000 tasks
	* E.g. perform this set of operations atomically
* **Imperative**: programmer states how it should be done
	* E.g. spawn N workers, assign work to threads from shared task queue
	* E.g. acquire a lock, perform operations, release lock

## Transactional Memory Semantics
* There are three key properties of memory transactions ⟶ A.I.S.
* **Atomicity**: All operations in transaction appear to execute as one atomic unit
	* Either all operations complete successfully, or none do
	* No partial results are visible to other threads
* **Isolation**: No other processors can observe partial results before transaction fully commits
* **Serializability**: The result of executing concurrent transactions is equivalent to executing them in some sequential order
	* The actual execution may be concurrent
	* But the final result must match some valid sequential ordering
![[Pasted image 20241203131609.png]]

# Transactional Memory
* In other words, many of the properties we maintained for a single address in a coherence memory system are maintained for a set of reads and writes in a transactional memory system.
![[Pasted image 20241203131945.png]]
* The consistency model of TM is sequential consistency (either all operations are executed in some sequential order, or none are)

## Motivation: HashMap
![[Pasted image 20241203132116.png]]

### Coarse-Grained
* To synchronize this, we can use **coarse-grained synchronization** ⟶ only allow one access to hash map at a time.
![[Pasted image 20241203132127.png]]

### Fine-Grained
* We can also use **fine-grained synchronization** ⟶ one lock per bucket instead of one lock per map.
	* Now thread safe, but incurs lock overhead even when synchronization is not needed (because we need to acquire lock every time we access)
	* **Disadvantage:** might be slower than course-grained in low-processor scenarios.

### Transactional Hash Map
* Basically the same as the coarse-grained lock case.
![[Pasted image 20241203132551.png]]
* Performance and scalability is now dependent on the implementation of the transactional memory system (i.e. implementation of `atomic`)

## Motivation: Tree Update
![[Pasted image 20241203132648.png]]

### Fine-Grained Locking
![[Pasted image 20241203132852.png]]

### Transactions
* **Case 1:** No intersection between the write and read states of each transaction
	* This means we can do both of these concurrently ⟶ depending on implementation, we can **reduce the contention** seen in fine-grained locking
		![[Pasted image 20241203132933.png]]

* **Case 2:** There is intersection. Transactions must be serialized.
		![[Pasted image 20241203133127.png]]

## Locks vs. Transactions
> [!NOTE] Key Idea of Transactions
> With transactions, non-conflicting transactions can be executed concurrently. We only need to serialize when there are conflicts.
>
> This reduces the overhead of locking.
![[Pasted image 20241203133255.png]]


## Example: Atomic and Doubly-Linked List
* With transactions, it is now extremely easy to make a doubly-linked list atomic ⟶ abstract it away
![[Pasted image 20241203133443.png]]

## Failure Atomicity
![[Pasted image 20241203133503.png]]
![[Pasted image 20241203133509.png]]

## Composability
* To synchronized composed synchronizations ⟶ we need some form of global policy
* In the example code, we acquire lock for $A$ then for $B$.
	* If one thread runs $transfer(A, B)$ and another does $transfer(B, A)$ ⟶ deadlock because can't acquire next lock.
![[Pasted image 20241203133631.png]]
![[Pasted image 20241203133823.png]]
![[Pasted image 20241203133754.png]]

## Summary: Advantages of TM
![[Pasted image 20241203133935.png]]
![[Pasted image 20241203134026.png]]

* In the example below, you cannot replace `synchronized` with `atomic` because **thread 2 needs to see changes within thread 1**
	* `atomic` states that regions are isolated ⟶ changes are not observable by other threads until it finishes committing.
	* alternatively, notice that the `synchronized` uses different locks.
![[Pasted image 20241203134200.png]]

# Implementing Transactional Memory
> [!NOTE] Recall: Semantics of TM
> 1. Atomicity
>    * At commit, all memory writes take effect at once
>    * In event of abort, none of the writes appear to take effect
> 2. Isolation
>    * No other code can observe writes before commit
> 3. Serializability
>    * Transactions seem to commit in a single serial order
>    * The exact order is not guaranteed though

# Data Versioning Policy
* **Goal:** Manage uncommitted (new) and previously committed (old) versions of data for concurrent transactions

* Eager versioning (undo-log based)
	* Write to memory immediately, hoping transaction won't abort
* Lazy versioning (write-buffer based)
	* Only write to memory when you are sure you did not fail.
![[Pasted image 20241209163220.png]]

## Eager Versioning (undo-log based)
* For every action, keep a log of the previous state.
	* When you commit: throw away undo log
	* When you abort: execute the undo log to revert changes to memory
![[Pasted image 20241209163031.png]]

## Lazy Versioning (write-buffer based)
* For every action, buffer that action until you commit.
	* When you commit: copy contents of write buffer into the memory
	* When you abort: discard the buffer
![[Pasted image 20241209163110.png]]

# Conflict Detection
* **Goal:** detect and handle conflicts between transactions.
	* **Read-write conflict:** transaction A reads addr `X`, which was written to by transaction B which is *pending but not yet committed*.
	* **Write-write conflict:** transactions A and B are both pending, and both write to `X`
* System must track a transaction's **read set** and **write set**
	* Read set ⟶ addrs read during transaction
	* Write set ⟶ addrs written to during transaction

## Pessimistic Detection
* Check for conflicts **immediately** during loads or stores.
	* Philosophy: “I suspect conflicts might happen, so let’s always check to see if one has occurred after each memory operation… if I’m going to have to roll back, might as well do it now to avoid wasted work.”
	* Undo-log versioning works well with this.
* **Contention manager** decides to **whether to stall or abort transaction** when a conflict is detected

> [!NOTE]
> * **Concept**: Assumes that conflicts are likely, so it prevents them by locking resources early.
> * **How it works**:
>     * Transactions acquire locks on data before reading or writing.
>     * These locks ensure that no other transaction can modify or access the locked data until the lock is released.
>     * Prevents conflicts from occurring but may lead to **deadlocks** or blocking if multiple transactions try to access the same resource.
> * **Pros**:
>     * Guarantees consistency and avoids conflicts completely during the transaction.
> * **Cons**:
>     * Higher overhead due to lock management.
>     * Lower concurrency, as transactions might block each other.
> * **Check**:
>     *


* Assume contention manager states that: **writer wins, causing other to abort.**
	* When T0 writes `A`, it causes any transaction that read `A` to abort.
	* When T0 reads `A`, if another transaction wrote before, it will stall until other is done.

### **Case 1: No conflict**
![[Pasted image 20241209163727.png]]

### **Case 2: Early Detect and stall**
* This is a **read-write conflict** ⟶ T0 wins because its the writer
	* T1 stalls because it read after T0 wrote.
	* When T1 continues after stall, it uses new value of `A` after T0 commits.
![[Pasted image 20241209164143.png|200]]

### **Case 3: Abort**
* This is a **read-write conflict** ⟶ T1 wins because its the writer
	* T0 is aborted due to the write from T1.
	* When T0 restarts, it tries to read again. It sees that T1 wrote in the past but has not committed, so it stalls (case 2).
![[Pasted image 20241209164501.png|200]]

### **Case 4: No Progress, livelock**
* This is a **write-write conflict** ⟶ they keep aborting each other, and neither is able to commit.
* The contention manager needs to implement a **livelock detector** to prevent this.
![[Pasted image 20241209164544.png|200]]


## Optimistic Detection
* Detect conflicts when a transaction attempts to commit.
	* Intuition: “Let’s hope for the best and sort out all the conflicts only when the transaction tries to commit”
* On a conflict, **give priority to committing transaction**
	* When we commit, compare **committing transaction's write set** with **read sets of all other** concurrent transactions. If no match, commit.
	* If conflict, other transactions may abort or stall
	* **Committing transaction does not abort. It's changes go through.**
* Write-buffer data versioning goes well with this.

> [!NOTE]
> * **Concept**: Assumes that conflicts between transactions are rare, so it allows transactions to proceed without locking resources.
> * **How it works**:
>     * Transactions work on a local copy of data (or in a transaction log).
>     * At the end of the transaction, it performs a **validation** phase to check whether conflicts occurred during execution (e.g., if other transactions modified the same data).
>     * If conflicts are detected, the transaction is rolled back and retried.
> * **Pros**:
>     * Low overhead when conflicts are rare (fewer locks).
>     * Higher concurrency, as multiple transactions can proceed without blocking.
> * **Cons**:
>     * Wasted work when conflicts are common, as transactions may frequently fail and need to retry.

### Case 1: No Conflict
* No conflict between sets
	* T0 read set is {A} and write set is {C}
	* T1 read set is {} and write set is {B}
![[Pasted image 20241209164933.png|200]]

### Case 2: Abort
* When T0 commits, there is a conflict ⟶ abort T1 (T1 is a **doomed** transaction)
	* T0 write set is {A}
	* T1 read set is {A}
* When T1 commits later on, no conflict
![[Pasted image 20241209165019.png|200]]

### Case 3: No Conflict
* Even though T1 has written `A`, because it commits later, no conflict.
* When T0 commits, no conflict:
	* T0 write set is {}
	* T1 read set is {}
![[Pasted image 20241209165402.png|200]]

### Case 4: Forward Progress
* When T1 commits ⟶ conflict, abort T0
	* T1 write set is {A}
	* T0 read set is {A}
* With pessimistic detection, we had livelock here. In this case, we can progress.
![[Pasted image 20241209165514.png|200]]

## Trade-offs
* Pessimistic conflict detection (a.k.a. “eager”)
	* Good: detect conflicts early (undo less work, turn some aborts to stalls)
	* Bad: no forward progress guarantees (livelock), more aborts in some cases
	* Bad: fine-grained communication (check on each load/store)
	* Bad: detection on critical path
* Optimistic conflict detection (a.k.a.“lazy” or “commit”)
	* Good: forward progress guarantees (much harder to livelock)
	* Good: bulk communication and conflict detection
	* Bad: detects conflicts late, can still have fairness problems
![[Pasted image 20241210114408.png]]
![[Pasted image 20241210114351.png]]
