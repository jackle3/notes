
# Abstractions for Synchronization
* Previous topic: machine-level atomic operations for synchronization
	* E.g. test-and-set, fetch-and-op, compare-and-swap, load linked-store conditional
* We used these to construct higher-level synchronization primitives:
	* Locks, barriers
	* Lock-free data structures
	* We've seen how its challenging to produce correct programs using these primitives (easy to create bugs that violate atomicity, deadlock, etc.)

* Today: using transactional memory as a higher-level synchronization primitive
## Whats the Problem with Locking?
* Locks force trade off between performance (degree of concurrency) and correctness (races, deadlocks, etc)
* To get a highly-concurrent program, you need either:
	* fine-grained locking ⟶ better but more likely to create bugs
	* coarser-grained locking ⟶ lower concurrency, but higher chance of correctness

## Review: Ensuring Atomicity via Locks
* Suppose you are doing deposits. If there can be concurrent deposits, we need ot synchronize it.
![[Pasted image 20241203131353.png]]

# Programming with Transactions
* Instead of explicitly locky, you **declare a set of operations/a region of instructions** to be atomic.
	* You leave it up to the system to implement this atomicity.
![[Pasted image 20241203131411.png]]

## Declarative vs. Imperative Abstractions
* **Declarative**: programmer defines what should be done
	* E.g. execute all these independent 1000 tasks
	* E.g. perform this set of operations atomically
* **Imperative**: programmer states how it should be done
	* E.g. spawn N workers, assign work to threads from shared task queue
	* E.g. acquire a lock, perform operations, release lock

## Transactional Memory Semantics
* There are three key properties of memory transactions ⟶ A.I.S.
* **Atomicity**: All operations in transaction appear to execute as one atomic unit
	* Either all operations complete successfully, or none do
	* No partial results are visible to other threads
* **Isolation**: No other processors can observe partial results before transaction fully commits
* **Serializability**: The result of executing concurrent transactions is equivalent to executing them in some sequential order
	* The actual execution may be concurrent
	* But the final result must match some valid sequential ordering
![[Pasted image 20241203131609.png]]

# Transactional Memory
* In other words, many of the properties we maintained for a single address in a coherence memory system are maintained for a set of reads and writes in a transactional memory system.
![[Pasted image 20241203131945.png]]
* The consistency model of TM is sequential consistency (either all operations are executed in some sequential order, or none are)

## Motivation: HashMap
![[Pasted image 20241203132116.png]]

### Coarse-Grained
* To synchronize this, we can use **coarse-grained synchronization** ⟶ only allow one access to hash map at a time.
![[Pasted image 20241203132127.png]]

### Fine-Grained
* We can also use **fine-grained synchronization** ⟶ one lock per bucket instead of one lock per map.
	* Now thread safe, but incurs lock overhead even when synchronization is not needed (because we need to acquire lock every time we access)
	* **Disadvantage:** might be slower than course-grained in low-processor scenarios.

### Transactional Hash Map
* Basically the same as the coarse-grained lock case.
![[Pasted image 20241203132551.png]]
* Performance and scalability is now dependent on the implementation of the transactional memory system (i.e. implementation of `atomic`)

## Motivation: Tree Update
![[Pasted image 20241203132648.png]]

### Fine-Grained Locking
![[Pasted image 20241203132852.png]]

### Transactions
* **Case 1:** No intersection between the write and read states of each transaction
	* This means we can do both of these concurrently ⟶ depending on implementation, we can **reduce the contention** seen in fine-grained locking
		![[Pasted image 20241203132933.png]]

* **Case 2:** There is intersection. Transactions must be serialized.
		![[Pasted image 20241203133127.png]]

## Locks vs. Transactions
> [!NOTE] Key Idea of Transactions
> With transactions, non-conflicting transactions can be executed concurrently. We only need to serialize when there are conflicts.
>
> This reduces the overhead of locking.
![[Pasted image 20241203133255.png]]


## Example: Atomic and Doubly-Linked List
* With transactions, it is now extremely easy to make a doubly-linked list atomic ⟶ abstract it away
![[Pasted image 20241203133443.png]]

## Failure Atomicity
![[Pasted image 20241203133503.png]]
![[Pasted image 20241203133509.png]]

## Composability
* To synchronized composed synchronizations ⟶ we need some form of global policy
* In the example code, we acquire lock for $A$ then for $B$.
	* If one thread runs $transfer(A, B)$ and another does $transfer(B, A)$ ⟶ deadlock because can't acquire next lock.
![[Pasted image 20241203133631.png]]
![[Pasted image 20241203133823.png]]
![[Pasted image 20241203133754.png]]

## Summary: Advantages of TM
![[Pasted image 20241203133935.png]]
![[Pasted image 20241203134026.png]]

* In the example below, you cannot replace `synchronized` with `atomic` because **thread 2 needs to see changes within thread 1**
	* `atomic` states that regions are isolated ⟶ changes are not observable by other threads until it finishes committing.
	* alternatively, notice that the `synchronized` uses different locks.
![[Pasted image 20241203134200.png]]

# Implementing Transactional Memory

> [!NOTE] Recall: Semantics of TM
> 1. Atomicity
>    - At commit, all memory writes take effect at once
>    - In event of abort, none of the writes appear to take effect
> 2. Isolation
>    - No other code can observe writes before commit
> 3. Serializability
>    - Transactions seem to commit in a single serial order
>    - The exact order is not guaranteed though
