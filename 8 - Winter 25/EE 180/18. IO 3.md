# Large Data Transfers
The simple approach is to use `ld/st` instructions.
	* Software moves *all* data between memory and I/O addresses
	* Simple and flexible, but wastes processor time moving data instead of doing other useful work

# Direct Memory Access (DMA)
A solution to allow data transfers to happen **without** involving the processor.
* A custom engine for data movement
	* Transfers blocks of data to or from memory without CPU intervention
	* DMA engines are available in processor chips and I/O chips
	* DMA engine acts as a bus initiator in bus-based systems

## **DMA Engine interface**
* The DMA engine is itself an I/O device
* It has registers or memory to describe transfers:
	* `from`, `to`, and `length` registers
	* It can have multiple of those registers, or have a queue of transfers
* It also has registers for status and control

## **DMA Operation**
1. Processor sets up DMA by supplying:
	* Identity of the device and the operation (read/write)
	* Memory address for the source and destination (usually physical addresses)
	* Number of bytes to transfer
	* **Note**: CPU continues with other work while DMA is transferring
2. DMA engine arbitrates for bus access
3. DMA engine starts transfer when data is ready
4. When transfer is complete or on error, DMA engine notifies processor (i.e. interrupt)
![[Pasted image 20250306135915.png]]

# Reading a Disk Sector
![[Pasted image 20250306140310.png]]
![[Pasted image 20250306140314.png]]
![[Pasted image 20250306140330.png]]

# DMA Issues
**Memory Pinning**
* DMA transfers usually use physical memory addresses directly
* Memory pages involved in DMA must be "pinned" (locked) in physical memory
* Without pinning, the OS might page out memory during transfer, causing:
	* Physical addresses given to DMA to become invalid
	* DMA to read/write incorrect memory locations
* Pinned pages stay in physical memory until transfer completes

**Memory Translation**
* Challenge: Virtual memory appears contiguous but physical pages are scattered. If DMA uses physical addresses, it must handle page boundaries.
* This complicates DMA transfers that span multiple pages
* Solutions:
	1. Limit transfers to one page at a time (simple but inefficient)
	2. Set up a chain of multiple page-sized transfers
		* DMA engine processes in sequence, interrupts once at the end
	3. Add I/O MMU to DMA engine to handle virtual addresses directly
		* Translate virtual addresses to physical addresses (requires a TLB in the DMA engine)
	4. Allocate physically contiguous memory (or use scatter-gather DMA for non-contiguous memory)

**Cache Coherence**
* Problem: With write-back caches, memory may be out of sync with cache because write-back caches do not update memory until the line is evicted.
	* When I/O reads: DMA must get latest data (might be in cache)
	* When I/O writes: DMA must update/invalidate old cached copies
* Solutions:
	* Software: OS flushes/write-backs relevant cache lines before DMA operations
		* Usually done with hardware (ISA) support
	* Hardware: Route DMA memory accesses for I/O devices through cache
		* Search the cache for copies and invalidate or write-back as needed
		* Bad for performance: while I/O searches cache, processor cannot use the cache
		* Works better with multi-level inclusive caches
			* These are caches where higher-level caches (e.g. L2) contain copies of  lower-level caches (e.g. L1)
			* Minimize conflicts by having processor and I/O devices search different caches:
				* Processor primarily searches L1 cache (until it misses)
				* I/O requests primarily search L2 cache (until it finds a copy of interest)

# Approaching I/O Problems
**As a latency problem**
* Calculate latency across the system (core ⟶ memory ⟶ I/O ⟶ …)
* Use this approach if the problem asks for *latency per request*
	* E.g. the latency of a critical operation on an unloaded system

**As a throughput problem**
* Maximizing the throughput at steady state (for a loaded system)
* Find the bottleneck/weakest link (lowest-bandwidth component)
* Configure system to operate at the bottleneck's rate
* Balance the remaining components in the system to maximize throughput
![[Pasted image 20250306142551.png]]

## Performance
The performance of an entire system depends on:
* **Processor cores**: How fast can the processor operate on the data?
* **Memory system bandwidth and latency**: How fast can processor move data from,multilevel caches? Main memory?
* **System interconnection**: I/O and memory buses, I/O controllers
* **I/O devices (disks)**: How fast can the I/O devices transfer data?
* **Software efficiency**: I/O device handler instruction path length, OS overhead, etc

# Example I/O Design Problem
![[Pasted image 20250306142743.png]]
![[Pasted image 20250306142753.png]]
![[Pasted image 20250306143001.png]]
