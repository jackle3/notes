
# Advanced Pipelining: Modern Processors
![[Pasted image 20250206142753.png]]

* We are allowed to do out-of-order execution because of **instruction-level parallelism**
![[Pasted image 20250206142923.png]]

## Deeper Pipelining
* We can increase the number of pipeline stages
	* This leads to fewer levels of logic per pipeline stage
	* Also leads to higher clock frequency (because each stage is faster, we can run the whole processor at a higher speed)
![[Pasted image 20250206144431.png]]
* **Issues**: branch delay, load delay, forwarding/stalls complexity

## Superscalar Processors
* Superscalar processors are processors that can execute multiple instructions in parallel
* They do this by having multiple functional and execution units
	* The ideal CPI is now 0.5 because every cycle, we finish execution for 2 instructions.
![[Pasted image 20250206144510.png]]

# Dynamic Scheduling
* Execute instructions out of order
	* Fetch multiple instructions per cycle using branch prediction
	* Figure out which instructions can be executed in parallel
* **Issue**: the instructions are using the same registers. If the `sub` executes before the `or`, then the `or` will use the wrong value.
	* This is a write-after-write hazard (`add` writes to `t0` first and `sub` writes to `t0` second)
![[Pasted image 20250206144808.png]]

## Register Renaming
* To fix the issue from before, we can **map** the registers to get rid of false dependencies.
	* There are more physical registers than the architectural registers (i.e. more than the 32 registers that the ISA gives)
![[Pasted image 20250206144918.png]]

## Modern MIPS Processors
![[Pasted image 20250211141438.png]]
* This processor is `16R4W`, meaning it has 16 read ports and 4 write ports
* Read ports allow the processor to read from registers
	* Each read port can read from one register per cycle
	* Having 16 read ports means we can read from up to 16 different registers in parallel each cycle
* Write ports allow the processor to write to registers
	* Each write port can write to one register per cycle
	* Having 4 write ports means we can write to up to 4 different registers in parallel each cycle
* The number of ports directly impacts instruction-level parallelism:
	* More read ports = more instructions can read their operands simultaneously
	* More write ports = more instructions can write their results simultaneously

![[Pasted image 20250211141445.png]]

## Caveats of Out-of-Order Processors
![[Pasted image 20250211142044.png]]
* When instructions are fetched and decoded, they are stored in the **reservation station** before they are dispatched to out-of-order execution.
* After out-of-order execution, they are placed into a **re-order buffer** to ensure in-order completion and retirement
* What can go wrong if we reorder instructions?
	* **Exceptions**: When executing out-of-order, an instruction may raise an exception (e.g. divide by zero, page fault). We need to ensure that exceptions are handled in the original program order, not the execution order.
		* The **re-order buffer helps maintain precise exceptions** by only committing instructions in-order.
	* **Mispredictions**: Branch mispredictions require rolling back speculative execution.
		* The **re-order buffer allows us to identify and squash all speculative instructions** after the mispredicted branch while preserving earlier instructions.

# Dynamic Branch Prediction
* We predict the direction of branches based on past behavior
	* Keep a table of branch behavior and look up to get prediction
* This table is called the *branch prediction buffer* (or *branch history table*)
	* Maps from the lower bits of the PC address to a 1 bit value
		* Value says whether the branch was taken or not the last time
	* Evaluate actual branch condition and correct if prediction was wrong
		* Recover by flushing pipeline and restarting fetch, and then reset prediction
	* We also often use branch prediction tables with 2 bit values — more accurate
![[Pasted image 20250211135220.png]]

## 2-Bit Branch Predictor State Machine
![[Pasted image 20250212101027.png]]
* The 2-bit branch predictor uses a state machine with 4 states to make more stable predictions:
	* States 0,1 predict the branch will be taken (T)
		* State 0: Strongly predict taken
		* State 1: Weakly predict taken
	* States 2,3 predict the branch will not be taken (N)
		* State 2: Weakly predict not taken
		* State 3: Strongly predict not taken
* Key advantages over 1-bit prediction:
	* More resistant to changing prediction — requires two wrong predictions to switch
	* Prevents thrashing between taken/not taken predictions
* The state transitions on each branch outcome:
	* When branch is taken (T): Move one state toward strongly taken (left)
	* When branch is not taken (N): Move one state toward strongly not taken (right)
	* Requires multiple opposite outcomes to change branch prediction (from taken to not taken)

## Branch Prediction Example
![[Pasted image 20250211140230.png]]
* Assume the 1-bit is initialized to `Not Taken` and the 2-bit is initialized to `Weakly Taken`

| Index | Actual      | 1-bit Branch Predictor                                 | 2-bit Branch Predictor                                             |
| ----- | ----------- | ------------------------------------------------------ | ------------------------------------------------------------------ |
| 0     | `Taken`     | Predicts `Not Taken` ⟶ Mispredict<br>Change to `Taken` | Predicts `Weakly Taken` ⟶ Correct<br>Change to `Strongly Taken`    |
| 1     | `Taken`     | Predicts `Taken` ⟶ Correct                             | Predicts `Strongly Taken` ⟶ Correct                                |
| 2     | `Taken`     | Predicts `Taken` ⟶ Correct                             | Predicts `Strongly Taken` ⟶ Correct                                |
| 3     | `Taken`     | Predicts `Taken` ⟶ Correct                             | Predicts `Strongly Taken` ⟶ Correct                                |
| 4     | `Not Taken` | Predicts `Taken` ⟶ Mispredict<br>Change to `Not Taken` | Predicts `Strongly Taken` ⟶ Mispredict<br>Change to `Weakly Taken` |

# Limits of Advanced Pipelining
![[Pasted image 20250211141623.png]]
* Branch missprediction is a significant contributor to wasted work.
![[Pasted image 20250211141637.png]]
* There are also tradeoffs in terms of perofrmance and power.
![[Pasted image 20250211141811.png]]
* Observe how the the CPI is decreased a lot due to pipeline stalls and memory hierarchy stalls.
![[Pasted image 20250211141814.png]]
