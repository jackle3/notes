# Memory
* Once we read the address, it gets decoded into multiple word lines (shown in red horizontal lines)
* The word lines intersect with bit lines (shown in green vertical lines) at memory cells
* When a word line is activated:
	* All memory cells along that row connect to their respective bit lines
	* The multiplexer (Mux) at the bottom selects which bit line's data to output
	* The write enable (WE) signal controls whether we are reading or writing to the selected memory cells
* This forms a memory bank structure where:
	* Each row represents one memory word
	* Each column represents one bit position
	* The decoder and multiplexer allow us to access any word in memory
![Pasted image 20250128144909](attachments/Pasted%20image%2020250128144909.png)
![Pasted image 20250128144953](attachments/Pasted%20image%2020250128144953.png)
![Pasted image 20250128145045](attachments/Pasted%20image%2020250128145045.png)
* To make sure the write enable goes up after the address and input data is stable:
	* **Option 1:** We `and` the `WE` signal with the inverse of the `CLK` signal
		* This means the write operation happens in the second half of the clock cycle:
			* First half (CLK high): Address and data signals propagate and stabilize
			* Second half (CLK low): WE signal enabled, allowing write to occur
		* By waiting half a clock cycle, we ensure the address and data are valid before writing
		* The next rising edge of the clock marks the start of the next instruction
	* **Option 2:** We add a delay element to the WE signal path
		* This introduces a small time delay after the address and data signals
		* The delay ensures WE is activated only after inputs are stable
		* Similar to Option 1 but uses dedicated delay hardware instead of clock gating

# Single Cycle Processor
* In a single cycle processor, each instruction must complete within one clock cycle.
* The `load` instruction is typically the slowest, taking 800 picoseconds to:
	* Read from memory, process the data, write back to registers
![Pasted image 20250128145059](attachments/Pasted%20image%2020250128145059.png)
* To ensure correct operation:
	* The clock period must be at least as long as the slowest instruction
	* We set it to 800 picoseconds to match the `load` timing
	* This gives us a clock frequency of 1.25 GHz (1/800ps)
* This means all instructions, even simple ones, must wait 800ps to complete — limiting overall processor performance
![Pasted image 20250128145201](attachments/Pasted%20image%2020250128145201.png)

## Variable Clock Single Cycle Processor
* You can implement a processor with a variable-length clock
* Depending on the program instruction mix, we can get a better CPU clock cycle.
* Issue: this is very hard to design at high speeds.
![Pasted image 20250128145207](attachments/Pasted%20image%2020250128145207.png)

# Pipelining
![Pasted image 20250130134709](attachments/Pasted%20image%2020250130134709.png)
* Filling period: edge on left, not all pipelines utilized
* Draining period: edge on right, not all pipelines utilized

# 5-Stage Pipeline
* Executing an instruction has 5 stages, each of which take one clock cycle.
![Pasted image 20250130134822](attachments/Pasted%20image%2020250130134822.png)
* To pipeline, we can overlap instructions in different stages.
	* This ensures all our hardware is used all the time.
	* Clock cycle is faster:
		* Originally, we had one cycle for the entire `lw` instruction
		* Now we break it into 5 cycles for each stage.
![Pasted image 20250130134851](attachments/Pasted%20image%2020250130134851.png)

### CPI
* The CPI is 1 ⟶ we are fetching and finishing one instruction per cycle
* The latency is 5 cycles ⟶ each instruction still takes 5 cycles to complete
![Pasted image 20250130142130](attachments/Pasted%20image%2020250130142130.png)

## Pipeline Datapath
* These pipeline registers (e.g. `IF/ID`, `ID/EX`) are not accessible by software.
* Pipelining is done by the hardware — the software is the same.
![Kapture 2025-01-30 at 14.00.03](attachments/Kapture%202025-01-30%20at%2014.00.03.gif)

## Control Signals
![Pasted image 20250130140839](attachments/Pasted%20image%2020250130140839.png)
![Pasted image 20250130140844](attachments/Pasted%20image%2020250130140844.png)
* There are multiple versions of the control signals propagated through the stages of the pipeline.
	* E.g. `ExtOp_rf` is the `ExtOp` control signal for the instruction currently in the `RF/ID` stage.
	* It will change names to `ExtOp_ex` when this instruction reaches the `EX` stage.
![Pasted image 20250130140849](attachments/Pasted%20image%2020250130140849.png)

## Pipelined Processor Diagram
![Pasted image 20250130141218](attachments/Pasted%20image%2020250130141218.png)

## MIPS ISA
![Pasted image 20250130141234](attachments/Pasted%20image%2020250130141234.png)

## Pipeline Performance
![Pasted image 20250130141332](attachments/Pasted%20image%2020250130141332.png)
* Both have the same CPI of 1.
	* In single-cycle, the clock cycle time is the time for the slowest instruction because we wait for the slowest instruction to finish before starting the next one.
	* In pipelined, the clock cycle time is the time for the slowest stage, since we can overlap instructions in different stages.
![Pasted image 20250130141354](attachments/Pasted%20image%2020250130141354.png)

# Pipelining Issues
* If pipelining improves clock cycle time while maintaining CPI=1, why not add more stages?
* Three main issues prevent unlimited pipelining:
	1. Some operations must complete within a single cycle
	2. In practice, CPI is not actually 1
		* Pipeline hazards and stalls increase effective CPI
	3. Each pipeline stage requires additional registers
		* More stages = more area overhead
		* Increased power consumption from:
![Pasted image 20250130142247](attachments/Pasted%20image%2020250130142247.png)
