# Efficiency
![](../../attachments/Pasted%20image%2020250313134827.png)
where $C$ is the capacitance of the circuit, $V_{dd}$ is the supply voltage, and $F$ is the clock frequency.

**Goal**: improving performance without increasing power, energy, or cost.
## Improving Performance
![](../../attachments/Pasted%20image%2020250313134924.png)

## Example: MIPS Processors
![](../../attachments/Pasted%20image%2020250313134937.png)
![](../../attachments/Pasted%20image%2020250313134943.png)

# Energy Overhead in Instructions
Consider the energy cost of a single RISC instruction:
* The `ADD` instruction takes 70 pJ, but only ~0.5 pJ is used for the actual addition.
	* Only 0.5/70 = 0.7% of energy goes to actual computation!
* The rest of overhead due to control logic, data movement, etc. is 69.5 pJ
![](../../attachments/Pasted%20image%2020250313135133.png)

In a full program with multiple instructions, there is also overhead for D-cache accesses, branch prediction, etc.
![](../../attachments/Pasted%20image%2020250313135230.png)

## Reducing Wasted Energy
### Vectorization
1. We can perform a large number of operations per instruction to amortize the I-cache, register file, and control logic overhead (e.g. **vector processors**)
![](../../attachments/Pasted%20image%2020250313135513.png)
![](../../attachments/Pasted%20image%2020250313135539.png)
![](../../attachments/Pasted%20image%2020250313135550.png)
![](../../attachments/Pasted%20image%2020250313135601.png)
![](../../attachments/Pasted%20image%2020250313135641.png)
![](../../attachments/Pasted%20image%2020250313135658.png)

### Locality
2. We can perform a large number of operations for each D-cache access (i.e. locality)
![](../../attachments/Pasted%20image%2020250313135521.png)

# Custom Hardware
**Processors are highly programmable**
* Can be used to implement any algorithm you can program
* Cost: instruction overhead, more wasted work/energy to support general-purpose execution

**Custom Hardware**
* Highly efficient, only contains the necessary components for a specific task
* Designed to run one algorithm really fast (i.e. not general-purpose)
* Contains algorithm-specific and domain-specific hardware
	* Specific mix of math and control units
	* Specific precision at each stage
	* Also does data transfer to and from the memory hierarchy in a more optimal manner
	* I.e. hardware defines complex dataflows and instructions to support the algorithm

## Example: Sobel Filter
![](../../attachments/Pasted%20image%2020250313135954.png)
On a general-purpose processor, it takes a lot of instructions to compute the Sobel filter.
![](../../attachments/Pasted%20image%2020250313140013.png)
We can design **custom hardware to compute Sobel** ⟶ one instruction per pixel
![](../../attachments/Pasted%20image%2020250313140121.png)

# Memory Concerns: Bandwidth Matching
Custom hardware can only **operate as fast as we can feed it data**
* If memory is too slow: accelerator must stall
* If accelerator is too slow: memory is idle, we can fix by adding more accelerators (or may it bigger via data parallelism)

**Goal**: match compute throughput with available memory bandwidth
![](../../attachments/Pasted%20image%2020250313140318.png)
![](../../attachments/Pasted%20image%2020250313140323.png)

## Example: Convolution Engine
There is a lot of data movement in convolution, but also a lot of data reuse:
![](../../attachments/Pasted%20image%2020250313140154.png)
* How many rows of data do we need to buffer?
	* For a 3x3 convolution kernel, we need to buffer 3 rows of the input image
	* This allows us to compute one output pixel by accessing a 3x3 window of the input
	* As we slide the window horizontally, we reuse most of the data from the previous computation
* How much new (including temporary) data do we need per pixel?
	* For each new output pixel, we only need to fetch 3 new input pixels (one for each row)
	* The rest of the input data is already buffered from previous computations
	* We also need to store temporary partial sums during the convolution operation

We create a **custom datapath** with a write buffer, shift registers, and tap registers to buffer the input data efficiently:
![](../../attachments/Pasted%20image%2020250313140600.png)
* Using this, we can compute one pixel per cycle of the processor ⟶ very fast!

# Managing Custom Hardware
* Think of the custom hardware as an I/O device ⟶ you give it input to compute, it gives you output
* Software manages the accelerator:
	1. Initiates Sobel computation
	2. Provides input and receives output
	3. Deals with errors in the accelerator

## DMA: Moving Data Between CPU and Hardware
**Direct Memory Access (DMA)**
* Streaming memory transfer mechanism
* Takes in a set of source memory addresses
* Takes in a MMIO target address on the accelerator
* Streams source memory words to target

**To write to and from custom HW:**
1. Processor gathers image addresses (Ideally in a contiguous physical chunk)
2. Transmits addresses to DMA
3. DMA writes data to accelerator and signals when complete
4. Accelerator computes on data
5. Accelerator DMAs results back to allocated memory space

## Dataflow of Custom Hardware
Data movements, especially DMA actions between main memory and custom hardware, account for a significant portion of the total energy.

Choosing the right dataflow is very important for optimizing energy efficiency! The options are:
* **Weight Stationary (WS)** – reduce movement of weights
	* Keep weights on the processing element itself: minimize weight read costs
* **Input Stationary (IS)** – reduce movement of inputs
	* Keep inputs on the processing element itself: minimize input read costs
* **Output Stationary (OS)** – reduce movement of partial sums
	* Keep partial sums on the processing element itself: minimize partial sum R/W costs
* **No Local Reuse (NLR)** – no local storage at the processing element (e.g. ALU) level
	* Use a global buffer of larger size (e.g. shared memory, etc.), minimize DRAM access
![](../../attachments/Pasted%20image%2020250313141356.png)
![](../../attachments/Pasted%20image%2020250313141416.png)
![](../../attachments/Pasted%20image%2020250313141500.png)

## Example: Choosing a Dataflow
You are designing a hardware accelerator for a neural network with the following specs:
* Total number of weights = 30M
* Number of input / output activations = 10M / 20M
* On-chip memory capacity = 5 MB
* Weight precision = 4-bit
* Input / output activation precision = 16-bit / 16-bit
What dataflow mechanism would you implement in your custom hardware for best energy efficiency?
1. Input stationary
2. Output stationary
3. Weight stationary
4. No local reuse

**Solution**:
We first calculate the total memory needed for the weights, inputs, and outputs:
* Total total memory needed for weights = 30M * 4-bit / 8 bits per byte = 15 MB
* Total memory for inputs = 10M * 16-bit / 8 bits per byte = 20 MB
* Total memory for outputs = 20M * 16-bit / 8 bits per byte = 40 MB
* Total memory needed = 15 MB + 20 MB + 40 MB = 75 MB
* On-chip memory capacity = 5 MB

Based on this, we move the most amount of data for outputs. Therefore, it's best to implement the **output stationary** dataflow.
* Because we only have 5 MB of on-chip memory, we would need to do some form of **tiling** to fit the outputs in memory.
* However, it's still best to keep the output stationary dataflow because we minimize the amount of data movement by keeping the outputs on the processing element itself.

# Custom Hardware Costs
![](../../attachments/Pasted%20image%2020250313142655.png)
![](../../attachments/Pasted%20image%2020250313142702.png)
![](../../attachments/Pasted%20image%2020250313142711.png)
![](../../attachments/Pasted%20image%2020250313142721.png)

# Reconfigurable Architectures: FPGAs
Custom hardware where the processing elements can be reconfigured to implement different algorithms (i.e. FPGAs)
![](../../attachments/Pasted%20image%2020250313142733.png)

## What Are FPGAs?
![](../../attachments/Pasted%20image%2020250313142816.png)
![](../../attachments/Pasted%20image%2020250313142936.png)

## Reconfigurable Compute Blocks
![](../../attachments/Pasted%20image%2020250313142829.png)
![](../../attachments/Pasted%20image%2020250313142851.png)
![](../../attachments/Pasted%20image%2020250313143014.png)
![](../../attachments/Pasted%20image%2020250313143039.png)
![](../../attachments/Pasted%20image%2020250313143402.png)

## FPGA Pros and Cons
**Pros:**
* More flexible and cheaper than custom hardware ⟶ same chip reused across designs
* Can be more efficient than a general-purpose processor (especially performance per watt)
* Great for circuit emulation and validation
**Cons:**
* Less efficient than custom hardware ⟶ mainly because PEs (logic blocks) are more spaced out, routing signals and interconnect between PEs
* Less programmable than a general-purpose processor
* Slow programming toolchain ⟶ requires synthesis, mapping, and configuration

# Acceleration in Real World
![](../../attachments/Pasted%20image%2020250313143433.png)
![](../../attachments/Pasted%20image%2020250313143448.png)
![](../../attachments/Pasted%20image%2020250313143455.png)

# Summary
![](../../attachments/Pasted%20image%2020250313143504.png)
![](../../attachments/Pasted%20image%2020250313143521.png)
