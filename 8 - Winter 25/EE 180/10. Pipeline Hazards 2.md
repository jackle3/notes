# Control Hazards
* Control hazards are similar to data hazards, but it's **dependencies on the** `PC`
	* Cannot fetch the next instruction if I don't know its address (`PC`)
	* Only worse: we use the `PC` at the beginning of the pipeline
		* Makes forwarding very difficult

# Branch Control Hazards
* To calculate the next `PC` for MIPS:
	1. Most instructions ⟶ `PC + 4`
		* Calculated in the IF (first) stage
	2. Jump
		* Must calculate new PC based on offset
		* We know the target of jump in ID stage, since:
			* The jump target is encoded in the instruction itself
			* We can decode and calculate it as soon as we have the instruction
	3. Branches:
		* Must first compare registers and calculate `PC + 4 + offset`
		* We know the target of branch in MEM stage, since:
			* Need to read registers in ID stage
			* Need to compare values in EX stage using ALU
			* Only after that do we know if branch is taken
# Control Hazard Solutions
1. **Stall on branches**
	* Wait until you know the branch target (branch CPI becomes 4)
	* Check for stall in ID stage
	* The CPI becomes 4 because:
		* For each branch instruction, we stall for 3 cycles waiting to resolve it
		* 1 cycle to execute the branch itself
		* So each branch takes 4 cycles total instead of 1
2. **Predict not-taken**
	* Assume branch is not taken and continue with PC+4
	* If branch is actually not taken:
		* No penalty, execution continues normally
	* If prediction was wrong:
		* Must nullify misfetched instructions
		* Restart execution from PC+4+offset
3. **Predict taken**
	* Assume branch is taken
	* More complex implementation:
		* Need to calculate and predict PC+4+offset early
	* If prediction was wrong:
		* Must nullify misfetched instructions
		* Restart execution from PC+4

## Optimization: Moving to ID Stage
* In the original branch control hazard, we have to stall for three cycles (branch control point is in the MEM stage)
![Pasted image 20250204144534](../../attachments/Pasted%20image%2020250204144534.png)
 * We can optimize this by moving the branch control point from the memory stage to the ID stage.
	 * This means the branch consumes two registers in its ID stage.
	 * This means succeeding instructions no longer have to stall as much.
	 * Note: the branch control point is the stage in the pipeline where we can first determine if a branch will be taken or not
* **Important**: We know if the branch is taken or not in the ID stage. We don't actually take the branch until the MEM stage.
![Pasted image 20250206134517](../../attachments/Pasted%20image%2020250206134517.png)
![Pasted image 20250206135538](../../attachments/Pasted%20image%2020250206135538.png)
![Pasted image 20250206141201](../../attachments/Pasted%20image%2020250206141201.png)
## Strategy: Delayed Branches
* Delayed branches are a technique where branch instructions don't take effect immediately:
	* When the processor encounters a branch instruction (like `beq`), it always executes the next instruction before actually taking the branch
	* This "delay slot" (the instruction after the branch) is guaranteed to execute regardless of whether the branch is taken or not
	* The compiler can take advantage of this by placing a useful instruction in the delay slot:
		* For example, an instruction that both paths of the branch would need
		* Or an instruction from inside the branch target that can be safely moved up
* This approach was used in early MIPS processors to simplify the hardware, though it makes the ISA more complex since programmers/compilers need to be aware of the delay slot
![Pasted image 20250206134932](../../attachments/Pasted%20image%2020250206134932.png)

## Data Hazards for Branches
* The branch can consume values when it's in the ID stage.
	* Before, we only forward to the EX stage. Now, we need to also forward to ID.
	* If we have other useful instructions, we don't stall on the branch because forwarding will work correctly.
![Pasted image 20250206135005](../../attachments/Pasted%20image%2020250206135005.png)
* If the comparison is from the preceding:
	* The branch needs to stall for one cycle so that it can get the forwarded data into its own ID stage.
![Pasted image 20250206135040](../../attachments/Pasted%20image%2020250206135040.png)
* If the load is immediately before the branch, then we stall for two cycles.
![Pasted image 20250206135138](../../attachments/Pasted%20image%2020250206135138.png)

## Branch CPI
* In "ID/Predict Taken", the CPI penalty is same as stalling because at the ID stage, we do not know if the branch is taken or not, so it's effectively the same as stalling.
* In "ID/Predict Not Taken", the CPI penalty is less because 65% of the time when the branch is taken, our guess is wrong so we stall for 1 cycle. 35% of the time, our guess is right and we don't stall.
* In "ID/Delayed Branches", the CPI penalty is least because even though we stall for 1 cycle, the penalty is only 50% because we can fill the single delay slot with a useful instruction.
![Pasted image 20250206135644](../../attachments/Pasted%20image%2020250206135644.png)

# Exceptions and Interrupts
![Pasted image 20250206140246](../../attachments/Pasted%20image%2020250206140246.png)
![Pasted image 20250206140254](../../attachments/Pasted%20image%2020250206140254.png)

## Handling Instructions
![Pasted image 20250206140306](../../attachments/Pasted%20image%2020250206140306.png)
![Pasted image 20250206140709](../../attachments/Pasted%20image%2020250206140709.png)

## Vectored Interrupts
* Have a vector as the interrupt table ⟶ table defines where to jump for each handler
![Pasted image 20250206141221](../../attachments/Pasted%20image%2020250206141221.png)

## Precise Exceptions
![Pasted image 20250206141415](../../attachments/Pasted%20image%2020250206141415.png)
* Precise exceptions have four key requirements:
	1. All instructions before the faulting instruction must have completed
	2. The faulting instruction itself must not have started execution
	3. No instructions after the faulting instruction should have started
		* No changes should have been made to architectural state (registers, memory)
* OS developers prefer precise exceptions because they:
	* Make exception handling predictable and deterministic
	* Enable easier program resumption and debugging
* In single-cycle designs, precise exceptions are simple:
	* Instructions execute one at a time with atomic state changes
	* Exception location is clearly defined
* In pipelined designs, precise exceptions are complex because:
	* Multiple in-flight instructions can modify state out of order
	* Multiple exceptions may occur simultaneously
	* Need hardware to track instruction order and handle state restoration

## Exceptions in a Pipeline
![Pasted image 20250206141628](../../attachments/Pasted%20image%2020250206141628.png)
* When an exception is hit, we need to nullify subsequent instructions
![Pasted image 20250206141644](../../attachments/Pasted%20image%2020250206141644.png)
* Pipeline diagram with exceptions:
	* Notice the `[IF, ID, EX].FLUSH` signals that are used to flush the instruction in that stage of the pipeline
	* When an exception occurs, we need to clear out (flush) instructions that are currently in the pipeline
	* The FLUSH signals accomplish this by:
		* IF.FLUSH: Clears the instruction being fetched
		* ID.FLUSH: Nullifies the instruction being decoded
		* EX.FLUSH: Cancels the instruction in execution
	* This ensures that no instructions after the excepting instruction can modify processor state
	* The pipeline can then safely jump to the exception handler without any unwanted side effects
	* When returning from the exception handler, execution can resume cleanly from the excepting instruction
![Pasted image 20250206141732](../../attachments/Pasted%20image%2020250206141732.png)

## Exception Example
![Pasted image 20250206142227](../../attachments/Pasted%20image%2020250206142227.png)
![Pasted image 20250206142123](../../attachments/Pasted%20image%2020250206142123.png)
![Pasted image 20250206142221](../../attachments/Pasted%20image%2020250206142221.png)

## Multiple Exceptions
* In a pipelined processor, multiple instructions are executing at the same time. This means that more than one instruction could trigger an exception simultaneously
* To handle this cleanly, we use a straightforward approach:
	* We process exceptions in the same order as the instructions that caused them
	* We wait until an instruction reaches a specific stage (usually MEM or WB) before handling its exception
	* If an instruction causes an exception, we cancel all instructions that came after it
	* This orderly approach is required to maintain "precise exceptions" - where the processor state is predictable when an exception occurs
